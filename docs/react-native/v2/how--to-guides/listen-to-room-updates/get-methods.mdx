---
title: Getter Methods
nav: 5.3
---

The `HMSSDK` instance provides several 'Getter' methods for obtaining the latest data of a Room, which can be used to update stale data in the app and re-render the user interface.

Let's look at the methods one by one:

### getRoom

The `getRoom` method is used to obtain information about the room you are currently in. This method returns a `promise` that resolves with an `HMSRoom` object.

```js{3}
try {
  // Latest `HMSRoom` object
  const room: HMSRoom = await hmsInstance.getRoom();

  console.log('getRoom Success: ', room);
} catch(error) {
  console.log('getRoom Error: ', error);
}
```

### getAuthTokenByRoomCode

The `getAuthTokenByRoomCode` method is used to generate an authentication token for the user to join or preview the meeting room. It accepts three parameter as follows -

1. roomCode: Room Code is a unique encrypted short code generated by 100ms for a given Role and Room. You can learn more about it in [Room Codes](/concepts/v2/concepts/rooms/room-codes/room-codes) docs
2. userId: [optional] Unique Id for the user, This will be encoded in the authentication token
3. endpoint: [optional] This is only required by 100ms Team for internal QA testing. You need not use `endpoint` parameter

This method returns a `promise` that resolves with an authentication token.

> To learn more about using `getAuthTokenByRoomCode` method while joining room or room preview, You can check [Join Room](/react-native/v2/how--to-guides/set-up-video-conferencing/join#generate-auth-token) docs

```js
try {
  // Auth Token generated for the given `roomCode`
  const token: string = await hmsInstance.getAuthTokenByRoomCode('abc-defg-hij'); // sample room code

  // Use this Auth token to Join or Preview HMSRoom
  console.log('getAuthTokenByRoomCode Success: ', token);

} catch(error) {
  console.log('getAuthTokenByRoomCode Error: ', error);
}
```

> You can learn more about authentication using Room Codes [here](/concepts/v2/concepts/rooms/room-codes/room-code-auth).

### getSessionMetaData

The `getSessionMetaData` method is used to retrieve the currently set session metadata. If no metadata has been set on the session, this method returns `null`.

```js{2}
try {
  const sessionMetadata: string | null = await hmsInstance.getSessionMetaData();

  console.log('getSessionMetaData Success: ', sessionMetadata);
} catch (error) {
  console.log('getSessionMetaData Error: ', error);
}
```

The `setSessionMetaData` method can be used to set session metadata.

### getRoles

The `getRoles` method is used to retrieve all of the roles available in the current room. This method returns a `promise` that resolves with a list of `HMSRole` objects.

```js{2}
try {
  const roles: HMSRole[] = await hmsInstance.getRoles();

  console.log('getRoles Success: ', roles);
} catch (error) {
  console.log('getRoles Error: ', error);
}
```

### getLocalPeer

The `getLocalPeer` method is used to retrieve the updated local peer object. This method returns a `promise` that resolves with a `HMSLocalPeer` object.

```js{2}
try {
  const localPeer: HMSLocalPeer = await hmsInstance.getLocalPeer();

  console.log('getLocalPeer Success: ', localPeer);
} catch (error) {
  console.log('getLocalPeer Error: ', error);
}
```

### getRemotePeers

The `getRemotePeers` method is used to retrieve all of the peers present in the current room. This method returns a `promise` that resolves with a list of `HMSRemotePeer` objects.

```js{2}
try {
  const remotePeers: HMSRemotePeer[] = await hmsInstance.getRemotePeers();

  console.log('getRemotePeers Success: ', remotePeers);
} catch (error) {
  console.log('getRemotePeers Error: ', error);
}
```

### isScreenShared

The `isScreenShared` method is used to retrieve the current 'screen sharing' status of the local peer. This method returns a `promise` that resolves to `true` if screen is being shared and `false` otherwise.

> You can learn more about the screen sharing feature in the [Screenshare](/react-native/v2/how--to-guides/set-up-video-conferencing/screenshare) documentation.

```js{2}
try {
  const screenShareStatus: boolean = await hmsInstance.isScreenShared();

  console.log('isScreenShared Success: ', screenShareStatus);
} catch (error) {
  console.log('isScreenShared Error: ', error);
}
```

### isPipModeSupported [Android Only]

The `isPipModeSupported` method is used to determine if the Android device supports Picture-In-Picture mode. This method returns a `promise` that resolves to `true` if PIP mode is supported and `false` otherwise.

> You can refer to the [Picture-In-Picture mode](/react-native/v2/how--to-guides/set-up-video-conferencing/render-video/pip-mode) documentation to learn more about this feature.

```js{2}
try {
  const isPIPSupported = await hmsInstance.isPipModeSupported();

  console.log('isPipModeSupported Success: ', isPIPSupported);
} catch (error) {
  console.log('isPipModeSupported Error: ', error);
}
```

### getAudioDevicesList [Android Only]

The `getAudioDevicesList` method is used to retrieve a list of available audio output devices on the device. This method returns a `promise` that resolves with a list of `HMSAudioDevice` enum values.

Note that this method is only available on the Android platform.

> You can refer to the [Audio Output Routing](/react-native/v2/how--to-guides/configure-your-device/speaker/audio-output-routing) documentation to learn more about this feature.

```js{12}
export enum HMSAudioDevice {
  SPEAKER_PHONE = 'SPEAKER_PHONE',
  WIRED_HEADSET = 'WIRED_HEADSET',
  EARPIECE = 'EARPIECE',
  BLUETOOTH = 'BLUETOOTH',
  AUTOMATIC = 'AUTOMATIC',
}

...

try {
  const audioDevicesList: HMSAudioDevice[] = await hmsInstance.getAudioDevicesList();

  console.log('getAudioDevicesList Success: ', audioDevicesList);
} catch (error) {
  console.log('getAudioDevicesList Error: ', error);
}
```

### getAudioOutputRouteType [Android Only]

The `getAudioOutputRouteType` method is used to retrieve the 'current audio output route type' on the device. This method returns a `promise` that resolves with `HMSAudioDevice` enum value.

Note that this method is only available on the Android platform.

> You can refer to the [Audio Output Routing](/react-native/v2/how--to-guides/configure-your-device/speaker/audio-output-routing) documentation to learn more about this feature.

```js{12}
export enum HMSAudioDevice {
  SPEAKER_PHONE = 'SPEAKER_PHONE',
  WIRED_HEADSET = 'WIRED_HEADSET',
  EARPIECE = 'EARPIECE',
  BLUETOOTH = 'BLUETOOTH',
  AUTOMATIC = 'AUTOMATIC',
}

...

try {
  const currentAudioOutputDevice: HMSAudioDevice = await hmsInstance.getAudioOutputRouteType();

  console.log('getAudioOutputRouteType Success: ', currentAudioOutputDevice);
} catch (error) {
  console.log('getAudioOutputRouteType Error: ', error);
}
```

### isAudioShared [Android Only]

The `isAudioShared` method is used to retrieve the current 'audio sharing' status of the local peer. This method returns a `promise` that resolves to `true` if audio is being shared and `false` otherwise.

> You can learn more about the audio sharing feature on both iOS and Android platforms in the [Audio Share](/react-native/v2/how--to-guides/set-up-video-conferencing/local-audio-share) documentation.

```js{2}
try {
  const audioShareStatus: boolean = await hmsInstance.isAudioShared();

  console.log('isAudioShared Success: ', audioShareStatus);
} catch (error) {
  console.log('isAudioShared Error: ', error);
}
```

### getAudioMixingMode [Android Only]

The `getAudioMixingMode` method is used to retrieve the current 'Audio Streaming mode' of the local peer. This method returns a `promise` that resolves with a value of the `HMSAudioMixingMode` enum.

Audio Streaming mode of the local peer can be of following types:

1. `HMSAudioMixingMode.TALK_ONLY`: Only data captured by the microphone will be streamed in the room.
2. `HMSAudioMixingMode.TALK_AND_MUSIC`: Data captured by the microphone and the audio currently being played back on the device will be streamed in the room.
3. `HMSAudioMixingMode.MUSIC_ONLY`: Only the audio currently being played back on the device will be streamed in the room.

Note that this method is only available on the Android platform.

> You can learn more about Audio Mixing Mode in [Audio Share](/react-native/v2/how--to-guides/set-up-video-conferencing/local-audio-share#android) docs of Android platform.

```js{10}
export enum HMSAudioMixingMode {
  TALK_ONLY = 'TALK_ONLY',
  TALK_AND_MUSIC = 'TALK_AND_MUSIC',
  MUSIC_ONLY = 'MUSIC_ONLY',
}

...

try {
  const currentAudioMixingMode: HMSAudioMixingMode = await hmsInstance.getAudioMixingMode();

  console.log('getAudioMixingMode Success: ', currentAudioMixingMode);
} catch (error) {
  console.log('getAudioMixingMode Error: ', error);
}
```
