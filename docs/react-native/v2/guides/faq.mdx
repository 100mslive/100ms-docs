---
title: FAQ
nav: 2.5
---

This page lists down frequently asked questions. If you want to add a new question or edit an older one, feel free to send us a PR.


## Could not invoke HMSSDK.build or HMSManager.build

![error](https://user-images.githubusercontent.com/56931905/174788439-53a39a54-847e-46f7-9104-7524b1547992.jpg)

This error generally appears in development mode due to hot reloading. When the peer has joined the room and then the app is hot reloaded from the terminal, the peer is still in the room and when he tries to join back this error occurs. To make sure this error does not occur you have to remove your peer from the room.

-   To avoid you can add `instance.leave()` function on the unmounting of the Home Screen, so whenever the app is hot reloaded which leads to unmounting of the Home screen the leave function is called.

```js section=CouldNotInvokeHMSManagerBuild sectionIndex=1
const onLeavePress = async () => {
    await instance
        ?.leave()
        .then((d) => console.log('Leave Success: ', d))
        .catch((e) => console.log('Leave Error: ', e));
};

useEffect(() => {
    return () => {
        onLeavePress();
    };
}, []);
```

-   If this error occurred you can either join through web app and remove the peer which is still present due to hot reloading or you can kill the app and rebuild it.


## "trackID" is undefined (HMSView is rendering blank view)

`Peer` objects can have undefined `trackID`. If you are trying to use `trackId` directly from `Peer` object, then you might endup with undefined `trackId` problem.

We recommend using `ON_TRACK_UPDATE` event for listening to track updates. When you receive `TRACK_ADDED` update type on this event, you can save received `track` and `peer` objects.

Then you can use `trackId` from `track` object to show video in `HMSView`. This way your `trackID` will never be undefined.

> Note: `ON_TRACK_UPDATE` event is emitted for both "Audio" and "Video" tracks. For rendering video usecase, you only need to consider events received for "Video" tracks.

Some Useful links:
 - [Render Video of Peer](https://www.100ms.live/docs/react-native/v2/features/render-video)
 - [HMSTrackUpdate Event Listener](https://www.100ms.live/docs/react-native/v2/features/event-listeners-enums#hms-track-update)

You can also refer to usage of `ON_TRACK_UPDATE` in our sample app for more clear example - TODO: Add sample app usage link


## Unable to Join Meeting or getting error on join / preview functions of HMS Instance

This problem can happen due to many reasons. To self-serve, We recommend you to check if:

- you are using correct `authToken` and `username`.

  > `authToken` must contain correct `roomId` and `role`. `role` should be lowercase.
  
  Also check out [Auth Token and Security Guide](https://www.100ms.live/docs/react-native/v2/foundation/security-and-tokens).

- you are calling static `build` function on `HMSSDK` class correctly. <strong>Do not create an instance of `HMSSDK` class yourself with `new` keyword</strong>.
  
  `build` function returns instance of `HMSSDK` class and also sets up sdk on native side.

  ```js
  import { HMSSDK } from '@100mslive/react-native-hms';

  const hmsInstance = await HMSSDK.build();
  ```

  Also check out [Join Room Guide](https://www.100ms.live/docs/react-native/v2/features/join)

- Meeting Joining link is not disabled


## UI components to test all the features and functionalities

We have UI components for all the features in our showcase apps.
You can clone our [example app](https://github.com/100mslive/react-native-hms) or [sample apps](https://github.com/100mslive/react-native-hms/tree/main/sample-apps) to quickly test features and experiment as per your use case.


## Customize Track Settings

You can customize Video and Audio track settings of Local Peer with `HMSTrackSettings`, `HMSVideoTrackSettings` and `HMSAudioTrackSettings` classes.

while setting up `HMSSDK` instance you can pass instance of `HMSTrackSettings` to `build` function available on `HMSSDK` class.

Refer to [Track Settings Guide](https://www.100ms.live/docs/react-native/v2/advanced-features/track-settings) for more info.

<strong>To customize more settings (other than defined on above mentioned classes) like video quality, aspect ratio, screenshare quality.</strong>

You can change all these and more in [100ms dashboard](https://dashboard.100ms.live/templates). Check out [Templates and Roles Guide](https://www.100ms.live/docs/react-native/v2/foundation/templates-and-roles)


## BLUETOOTH_CONNECT permission error/warning

On Android 12 devices, new Bluetooth permissions have been added to interact with other nearby Bluetooth devices. To fix this error -

1. Declare `BLUETOOTH_CONNECT` permission in AndroidManifest.xml file.

```xml
  <uses-permission android:name="android.permission.BLUETOOTH_CONNECT" />
```

2. The `BLUETOOTH_CONNECT` permission is runtime permission. Therefore, you must also request user approval at runtime before you join a call or display a preview in your app, like we do for Camera and Audio Permissions.
  
  We suggest using [react-native-permission](https://www.npmjs.com/package/react-native-permissions) to acquire permissions from both platforms.

  Check out official [Android Bluetooth Permissions](https://developer.android.com/guide/topics/connectivity/bluetooth/permissions) page.

  You can also check [Our Android Integration Guide](https://www.100ms.live/docs/react-native/v2/features/integration#for-android) and permission related code in our [Quickstart Sample App](https://github.com/100mslive/react-native-hms/tree/main/sample-apps)


## Using HMS with another WebRTC library

WebRTC is a core dependency of 100ms SDKs. While building your Real Time Audio Video apps, developers tend to utilize multiple libraries. So it can happen that some another package also has WebRTC as a dependency. In this scenario, your app might emit compile time errors, crash at run time or have unexpected behaviours. This usually happens due to multiple WebRTC instances within the app. To avoid these issues, it's recommended to only add 100ms package & remove any other packages that also depend on WebRTC. 100ms provides a rich set of features which you can easily customize to build your ideal Audio Video experiences.


## Expo Support

Yes, Expo is supported by 100ms React Native SDK. You can follow our [Expo Setup Guide](https://www.100ms.live/docs/react-native/v2/features/integration#expo-setup) to complete your setup.


## Change Streaming Video Aspect Ratio

Default Aspect Ratio of Streaming Video is 16:9. This can show many Peer Tiles in your streaming video.

You can change Aspect Ratio of Streaming video from -

[100ms Dashboard](https://dashboard.100ms.live/dashboard) > `Templates > Select a Template > Destinations tab > scroll down to Live Streaming > "Customize stream video output"`

You may want to change default ratio as per your use case. for example, If you have only one Tile in your stream video, then you can make video aspect ratio as same as Peer Tile acpect ratio.

This will give your Stream Viewers very nice watching experience.


## How to know if Local Peer is HLS Stream Viewer?

There is no fixed way to check this.

One option can be to check if Local Peer has the role which you created for HLS Stream Viewers.

```js
// Role name created for HLS Stream Viewers in the Room Template
const roleForStreamViewers = 'hls-viewer';

// Checking if Local Peer has the Viewers role.
const isHLSViewer = localPeer.role?.name === roleForStreamViewers;

// If Local Peer is a Stream Viewer, Show Stream Video Player to user.
if (isHLSViewer) {
  return <VideoPlayer {...} />
}
```


## How to Mute/Unmute Specific or All Remote Peers?

100ms have `changeTrackState` APIs to request mute or unmute remote peers.

Refer to [Change Track State](https://www.100ms.live/docs/react-native/v2/features/change-track-state) API docs to learn more.

To Mute all Remote Peers at once, you can refer [here](https://www.100ms.live/docs/react-native/v2/features/change-track-state#mute-all-remote-audio-tracks).


## How to Mute/Unmute Specific or All Remote Peers only locally?

When you mute audio or video of remote peer locally, you won't be able to hear or see the remote peer but it will be still audible and visible to others.

100ms have "Playback Allowed" APIs to mute or unmute remote peers locally.

Refer to [Playback Allowed](https://www.100ms.live/docs/react-native/v2/features/change-track-state) API docs to learn more.

To locally mute all Remote Peers at once, you can refer [here](https://www.100ms.live/docs/react-native/v2/features/playback-allowed#local-mute-all-remote-peers-audio).


## Restrict Remote Peer from Unmuting after Muting them

Once you [mute a Peer](https://www.100ms.live/docs/react-native/v2/features/mute), they can unmute themselves. To prevent peers from unmuting themselves, You should [change their role](https://www.100ms.live/docs/react-native/v2/features/change-role) to a `Role` which has has less [publishing permissions](https://www.100ms.live/docs/react-native/v2/foundation/templates-and-roles#publish-strategies) as per your use case instead of muting the peer.


## Enable PIP Mode automatically when user leaves app

Currently, Enabling [Picture in Picture (PIP) mode](https://www.100ms.live/docs/react-native/v2/features/pip-mode) automatically (i.e. without calling any function) is not supported.

We recommend enabling Picture in Picture (PIP) mode (by calling `enablePipMode` function) **while app is active**, on a button click or programatically.


## Enable PIP Mode in iOS device.

[Picture in Picture (PIP) mode](https://www.100ms.live/docs/react-native/v2/features/pip-mode) is not supported in iOS devices due to lack of permission of using [multitasking-camera-access](https://developer.apple.com/documentation/bundleresources/entitlements/com_apple_developer_avfoundation_multitasking-camera-access?language=objc#discussion) entitlement.

We are working on making this work. Thanks for your patience.


## Using HMSSDK Instance in nested components without passing as props

**Don't call `HMSSDK.build` function just to get the `hmsInstance` in nested components without prop drilling to use various APIs.**

`HMSSDK.build` creates and returns new instances of sdk each time you call it. It is not returning the previously created sdk instance.

We recommend using State Management solutions like Redux or Context API to save your originally created `hmsInstance` into store and use this stored instance in your nested components.


## How many HMSView can be rendered?

We recommend rendering seperate HMSView for each `trackId`. It means If you have 50 peers with trackIds in a room, then you will render 50 HMSView for each peer.

This can have an impact on your apps' performance. Therefore, since ideally maximum 4-6 HMSView should be visible at a time because of small screen size of mobile devices.

You can use [FlatList](https://reactnative.dev/docs/flatlist) to render HMSView for large list of peers, this way HMSView that are not in visible area will never be mounted and HMSViews that goes out of visible area will be unmounted.

By using FlatList you are improving your apps' performance and rendering seperate HMSView for each `trackId`.


## setup Example app

Follow following steps:

1. clone [100ms React Native repo](https://github.com/100mslive/react-native-hms)

2. In the project root, run `npm install`

3. Go to the example folder, `cd example`

4. In the example folder, run `npm install`

5. To run on Android, run `npx react-native run-android`

  You can run example app on Android Emulator using "deviceId" option, run `npx react-native run-android --deviceId <device_id_here>`

6. To run on iOS,

  a. first install the pods in iOS folder, `cd ios && pod install && cd ../`
    if error `cd ios && arch -x86_64 pod install && cd ../`

  b. set the Correct Development Team in Signing & Capabilities (This is not necessary for running app on iOS simulator)

  c. exclude architectures in Build Settings of Project and Pods ([more info](https://stackoverflow.com/a/65399525)) (mention Xcode version?)

  b. run `npx react-native run-ios`

  You can run example app on iOS Simulator using "simulator" option, run `npx react-native run-ios --simulator <simulator_name_here>`.

Above steps are also listed [here](https://github.com/100mslive/react-native-hms#-run-example-app)

