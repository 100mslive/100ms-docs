---
title: React Native Quickstart Guide
nav: 2.1
---

## Overview

This guide will walk you through simple instructions to create a video conferencing app using 100ms React Native SDK and test it using an emulator or your mobile phone.

Please check our [basic concepts guide](../foundation/basics) to understand the concepts like rooms, templates, peers, etc.

This guide contains instructions for two approaches to get you started with 100ms React Native SDK:

1. [Create a sample app](#create-a-sample-app) â€” instructions to create a react native app quickly with a complete code sample.
2. [Building step-by-step](#building-step-by-step) â€” instructions to walk you through the implementation of the app in a step-by-step manner.

You can also check our [basic sample app](https://github.com/100mslive/react-native-hms/tree/develop/sample-apps/rn-quickstart-app) on GitHub.

Check out the full-fledged example app implementation in the [100ms React Native SDK GitHub repository](https://github.com/100mslive/react-native-hms/tree/main/example) showcasing multiple features provided by 100ms.


## Create a sample app

This section contains instructions to create a simple React Native video conferencing app. We will help you with instructions to understand the project setup and complete code sample to implement this quickly.

<div className="steps-container">

### Prerequisites

- A [100ms account](https://dashboard.100ms.live/register) if you don't have one already.
- Working [React Native Development Environment](https://reactnative.dev/docs/environment-setup) for React Native CLI
- Familiar with basics of [React Native](https://reactnative.dev/docs/getting-started).
- [VS code](https://code.visualstudio.com/) or any other IDE / code editor

### Create a React Native app

Once you have the prerequisites, follow the steps below to create a React Native app. This guide will use [VS code](https://code.visualstudio.com/) but you can use any code editor or IDE.

1. Open your Terminal and navigate to directory/folder where you would like to create your app.

2. Run below command to create React Native app:
    
  ```bash
  npx react-native init HMSSampleApp --version 0.68.5 --npm && cd ./HMSSampleApp
  ```

3. Once the app is created, open it in VS code

4. Test run your app
            
    <Tabs id="test-run-sample-app" items={['iOS', 'Android']} />

    <Tab id="test-run-sample-app-0">

      ```bash tab=iOS
      npx react-native run-ios --simulator="iPhone 14"; npx react-native start
      ```

    </Tab>

    <Tab id="test-run-sample-app-1">

      ```bash tab=Android
      npx react-native run-android; npx react-native start
      ```

    </Tab>

    or follow Run instructions printed in terminal


### Install the 100ms React Native library

After the Test run of your app is successful, You can install [100ms React Native library](https://www.npmjs.com/package/@100mslive/react-native-hms) and [react-native-permissions](https://www.npmjs.com/package/react-native-permissions) in your app.

```bash
npm install --save @100mslive/react-native-hms react-native-permissions
```

### Complete code example

Now that your project setup is complete, let's replace the code in the lib/main.dart file with the complete code sample below -

### Fetch token to join the Room

To test audio/video functionality, you need to connect to a 100ms room; Please check the following steps for the same -

1. Navigate to your [100ms dashboard](https://dashboard.100ms.live/dashboard) or [create an account](https://dashboard.100ms.live/register) if you don't have one.
2. Use the `Video Conferencing Starter Kit` to create a room with a default template assigned to it to test this app quickly.
3. Go to the [Rooms page](https://dashboard.100ms.live/rooms) in your dashboard, click on the `Room Id` of the room you created above, and click on the `Join Room` button on the top right.
4. You will see 100ms demo URLs for the roles created when you deployed the starter kit; you can click on the 'key' icon to copy the token and update the `AUTH_TOKEN` variable in "App.js" file.
  > Token from 100ms dashboard is for testing purposes only, For production applications you must generate tokens on your own server. Refer to the [Management Token section](../foundation/security-and-tokens#management-token) in Authentication and Tokens guide for more information.

<video loop="true" autoplay="autoplay" controls="controls" id="vid" muted>
    <source src="/docs/guides/update-token-flutter.mp4" type="video/mp4" />
</video>
<br />

### Test the app

Follow the instructions in one of the tabs below based on the target platform you wish to test the app.

<Tabs id="run-sample-app" items={['iOS', 'Android']} />

<Tab id="run-sample-app-0">

##### Native file changes

1. Allow camera, recording audio and internet permissions

  Add the below snippet in the `info.plist` file -
    
  ```xml:Info.plist section=ForIOSPermissions sectionIndex=1
  <key>NSCameraUsageDescription</key>
  <string>Please allow access to Camera to enable video conferencing</string>

  <key>NSMicrophoneUsageDescription</key>
  <string>Please allow access to Microphone to enable video conferencing</string>

  <key>NSLocalNetworkUsageDescription</key>
  <string>Please allow access to network usage to enable video conferencing</string>
  ```

  Add the below snippet in the `ios/Podfile` file -
    
  ```json{5-8}:Podfile
    # An absolute path to your application root.
    :app_path => "#{Pod::Config.instance.installation_root}/.."
  )

  permissions_path = '../node_modules/react-native-permissions/ios'

  pod 'Permission-Camera', :path => "#{permissions_path}/Camera"
  pod 'Permission-Microphone', :path => "#{permissions_path}/Microphone"

  target 'HMSSampleAppTests' do
    inherit! :complete
  ```

2. Change ios target platform version to '13.0' in the `ios/Podfile` file
    
  ```json{4}:Podfile
  require_relative '../node_modules/react-native/scripts/react_native_pods'
  require_relative '../node_modules/@react-native-community/cli-platform-ios/native_modules'

  platform :ios, '13.0'
  install! 'cocoapods', :deterministic_uuids => false
  ```

##### Build and run the app

Once you've made the above changes, your app is ready for testing. You can build the app and run it in a simulator.

1. Install pods
    
  ```bash
  cd ios && pod install && cd ../
  ```

2. Build the App
    
  ```bash
  npx react-native run-ios --simulator="iPhone 14";
  ```

3. Start Metro Bundler if it is not already started
    
  ```bash
  npx react-native start
  ```

> If you see any permission related error, then check out `react-native-permissions` library [setup guide](https://github.com/zoontek/react-native-permissions#setup)

Now, after you click `join`, you should be able to see yourself (iOS simulator doesn't support actual video, you can connect an actual device to see your video in real-time). You can join the room using a browser as the second peer to check audio/video transactions between two or more peers.

</Tab>

<Tab id="run-sample-app-1">

##### Native file changes

1. Allow camera, recording audio and internet permissions by adding the below snippet to the `AndroidManifest.xml` file (at the application tag level).

  ```xml section=androidPermissions
  <uses-feature android:name="android.hardware.camera"/>

  <uses-feature android:name="android.hardware.camera.autofocus"/>

  <uses-permission android:name="android.permission.CAMERA"/>

  <uses-permission android:name="android.permission.CHANGE_NETWORK_STATE"/>

  <uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS"/>

  <uses-permission android:name="android.permission.RECORD_AUDIO"/>

  <uses-permission android:name="android.permission.INTERNET"/>

  <uses-permission android:name="android.permission.ACCESS_NETWORK_STATE"/>

  <uses-permission android:name="android.permission.FOREGROUND_SERVICE" />

  <uses-permission android:name="android.permission.BLUETOOTH" android:maxSdkVersion="30" />

  <uses-permission android:name="android.permission.BLUETOOTH_SCAN" />

  <uses-permission android:name="android.permission.BLUETOOTH_ADVERTISE" />

  <uses-permission android:name="android.permission.BLUETOOTH_CONNECT" />
  ```

2. Change `minSdkVersion` to 21 in the `android/build.gradle` file
    
  ```json{4}:build.gradle
  buildscript {
    ext {
      ...
      minSdkVersion = 21
      ...
    }
  }
  ```


##### Build and run the app

Once you've made the above changes, your app is ready for testing. You can build the app and run it in an emulator or an actual android device.

```bash
npx react-native run-android; npx react-native start
```

Now, after you click `join`, you should be able to see yourself (android emulator doesn't support actual video, you can connect an actual device to see your video in real-time). You can join the room using a browser as the second peer to check audio/video transactions between two or more peers.

</Tab>

</div>

<div style={{ marginBottom: 30 }}>
  <video loop="true" autoplay="autoplay" controls="controls" id="vid" muted>
      <source src="/docs/guides/join-room-flutter-android.mp4" type="video/mp4" />
  </video>
</div>


## Building step-by-step

In this section, We'll walk through what the above code does.

<div className="steps-container">

### Handle device permissions

We need permission from the user to access the media from the user's device. We must urge the user to grant permission to access camera, microphone, and bluetooth devices. We use the [react-native-permissions](https://www.npmjs.com/package/react-native-permissions) library that provides a cross-platform (iOS, Android) API to request permissions and check their status.

Please ensure to add permissions in the `AndroidManifest.xml` file for android and `info.plist` file for iOS. Check [test the app section](#test-the-app) for more information.

```js
console.log('Permissions Code Snippet here');
```

### Implement Join screen

This section will help you create the join screen user interface. To keep it simple for the quickstart, we have not created many UI elements; you can refer to the [sample app implementation](https://github.com/100mslive/react-native-hms/blob/develop/sample-apps/rn-quickstart-app/src/screens/Welcome/index.tsx) for a complete Preview/Join user interface.

```js
console.log('Join button Code Snippet here');
```

### Implement Room screen

100ms SDK provides various events, the client apps can subscribe to these events to get updates happening in the room after a user has joined.

To join a room, you need to create an `HMSConfig` instance and use that instance to call the join method of `HMSSDK` instance.

> **Note:** An `App token` is required to authenticate a room join request from your client-side app. Please ensure to set the `AUTH_TOKEN` variable value with correct "Auth Token" by fetching it from your dashboard. Check [fetch token to join a room section](#fetch-token-to-join-the-room) for more information. <br/> Read more about authentication and tokens in [this guide](../foundation/security-and-tokens)

You can check the below code snippet to create UI to show the video tiles of local and remote peers.
// TO CHECK: HMSUpdateListener plays a significant role in rendering video or displaying any information regarding the room.

```js
console.log('Room screen Initialization Code Snippet');
```

### Listen to Join and Peer Updates

The 100ms SDK emits:

- `HMSUpdateListenerActions.ON_JOIN` event when the user has joined the room successfully, and
- `HMSUpdateListenerActions.ON_PEER_UPDATE` event when any change happens for any Peer in the Room.

Our application must subscribe to these events to get the updates.

Check out the [Event Listener Enums](../features/event-listeners-enums#hmspeerupdate) docs to understand the update types emitted by the SDK for `HMSUpdateListenerActions.ON_PEER_UPDATE` event.

```js
console.log('on_JOIN and ON_PEER_UPDATE listeners Code Snippet');
```

### Listen to Track Updates

The 100ms SDK emits `HMSUpdateListenerActions.ON_TRACK_UPDATE` event when any change happens for any Track in the Room. Our application must subscribe to this event to get the track updates.

Check out the [Event Listener Enums](../features/event-listeners-enums#hmstrackupdate) docs to understand the update types emitted by the SDK for `HMSUpdateListenerActions.ON_TRACK_UPDATE` event.

```js
console.log('ON_TRACK_UPDATE listeners Code Snippet');
```

### Listen to Other Updates

The 100ms SDK emits various other events to handle different scenarios in the app. For example, you can use `HMSUpdateListenerActions.ON_ERROR` event to get errors from `HMSSDK`.

Check out the [Event Listeners](../features/event-listeners) docs to know more about events emitted by the SDK.

```js
console.log('ON_ERROR listener Code Snippet');
```

### Render Video in a Tile

We are taking use of `PeerTrackNode` class to render video and avatar of peers. Let's take a look at interface for `PeerTrackNode` class -

```js
interface PeerTrackNode {
  id: string; // Unique ID for each peer and track combination
  peer: HMSPeer; // `HMSPeer` object of peer
  track?: HMSTrack; // `HMSTrack` object of video track of the peer
}
```

To display a video track, You can simply get the `trackId` of the Video Tracks in `PeerTrackNode` object and pass it to `HmsView` component. If `track` in `PeerTrackNode` object is undefined or null then you can render avatar or name initials of the peer from the `peer` property in `PeerTrackNode`.

Check the [Render Video](../features/render-video) guide for more information.

```js
console.log('Tile Rendering Code Snippet');
```

### Render Video Tiles for Peers

You can create a **list of `PeerTrackNode` objects** (mentioned in [Render Video in a Tile](#render-video-in-a-tile) step) for each peer and track combination and then use this list to render Tiles for all the `PeerTrackNodes` objects. We recommend using [FlatList](https://reactnative.dev/docs/flatlist) component to render multiple Tiles, this ensures uniques Tiles are created for each trackId.

```js
console.log('Flatlist with list of PeerTrackNodes Code Snippet');
```

### Test App

You can refer to the [test the app section](#test-the-app) to test your app for android or iOS platform.

</div>


## Next Steps

We have multiple example apps to get you started with 100ms React Native SDK -

### Basic example

For a basic example, see the [React Native Quickstart Sample App](https://github.com/100mslive/react-native-hms/tree/develop/sample-apps/rn-quickstart-app) on GitHub.

### Full-fledged example

You can also check out the full-fledged example app implementation in the [100ms React Native SDK github repository](https://github.com/100mslive/react-native-hms/tree/main/example) showcasing multiple features provided by 100ms.

### Check Deployed Sample Apps

You can download and check out the 100ms React Native deployed apps -

ðŸ¤– Download the Sample Android App [here](https://appdistribution.firebase.dev/i/7b7ab3b30e627c35)

ðŸ“² Download the Sample iOS App [here](https://testflight.apple.com/join/v4bSIPad)


-------------------------------------------------------------------------------------------------------------------------


## Getting started

Hello there! In this guide, we'll build a video conferencing application using our React Native SDK. We'll be using functional components with the powerful hooks provided by our SDK and build an app where you can have video call with your friends.

## Prerequisites

To get started you should be familiar with basics of [React Native](https://reactnative.dev/).

## Installing the dependencies

```bash section=InstallingTheDependencies sectionIndex=1
npm install --save @100mslive/react-native-hms
```

## Permissions

### For Android Permissions

Add following permissions in `AndroidManifest.xml`

```xml section=ForAndroidPermissions sectionIndex=1
<uses-feature android:name="android.hardware.camera"/>

<uses-feature android:name="android.hardware.camera.autofocus"/>

<uses-permission android:name="android.permission.CAMERA"/>

<uses-permission android:name="android.permission.CHANGE_NETWORK_STATE"/>

<uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS"/>

<uses-permission android:name="android.permission.RECORD_AUDIO"/>

<uses-permission android:name="android.permission.INTERNET"/>

<uses-permission android:name="android.permission.ACCESS_NETWORK_STATE"/>

<uses-permission android:name="android.permission.FOREGROUND_SERVICE" />

<uses-permission android:name="android.permission.BLUETOOTH" android:maxSdkVersion="30" />

<uses-permission android:name="android.permission.BLUETOOTH_SCAN" />

<uses-permission android:name="android.permission.BLUETOOTH_ADVERTISE" />

<uses-permission android:name="android.permission.BLUETOOTH_CONNECT" />
```

You will also need to request Camera and Record Audio permissions at runtime before you join a call or display a preview. Please follow [Android Documentation](https://developer.android.com/training/permissions/requesting#request-permission) for runtime permissions.

### For iOS Permissions

Add following lines in `Info.plist` file

```xml section=ForIOSPermissions sectionIndex=1
<key>NSCameraUsageDescription</key>
<string>Please allow access to Camera to enable video conferencing</string>
<key>NSMicrophoneUsageDescription</key>
<string>Please allow access to Microphone to enable video conferencing</string>
<key>NSLocalNetworkUsageDescription</key>
<string>Please allow access to network usage to enable video conferencing</string>
```

## Concepts

-   Room: When we join a conference call, the participants are said to be in a video call room.
-   Peer: A participant in the video call. You are the local peer while others are remote peers.
-   Track: Media. There are two types of track a peer can have - audio and video.

## Initializing the SDK

Call the function given below to initialise the SDK

```js section=InitializingTheSDK sectionIndex=1
import { HMSSDK } from '@100mslive/react-native-hms';

const hmsInstance = await HMSSDK.build();
```

This function will return the instance of HMSSDK that will be used for calling various functions and accessing data.

## Add event listeners

Add event listeners for all the events you want updates from such as onPreview, onJoin, onError etc. The actions can be found in HMSUpdateListenerActions class.

The event handlers are the way of handling any update happening in hms. It is advised to attach all the event listeners so you don't miss any update.

```js section=AddEventListeners sectionIndex=1
import { HMSUpdateListenerActions } from 'react-native-hms';

// instance acquired from build() method
hmsInstance.addEventListener(
    HMSUpdateListenerActions.ON_PREVIEW,
    onPreview // function that will be called on Preview success
);

hmsInstance.addEventListener(HMSUpdateListenerActions.ON_ERROR, onError);

hmsInstance.addEventListener(HMSUpdateListenerActions.ON_JOIN, onJoin);
```

## Joining a room

To join a room 3 fields are required:

-   `username`: The name of the user. This is the value that will be set on the peer object and be visible to everyone connected to the room.
-   `authToken`: A client-side token that is used to authenticate the user. You can read about how to generate this token [here](https://docs.100ms.live/react-native/v2/guides/token).
-   `userID`: A unique ID that will be used to identify user.
-   `roomID` (optional): The ID of the room that you wanna join

```js section=JoinRoom sectionIndex=1
import { HMSConfig } from 'react-native-hms';

// instance acquired from build() method
const HmsConfig = new HMSConfig({ authToken, userID, roomID, userName });

hmsInstance.preview(HmsConfig); // to start preview
// or
hmsInstance.join(HmsConfig); // to join a room
```

## Leaving the room

Before we go ahead with adding video, let us add a way to leave the room as well. We can call the leave method on hmsActions to leave the room.

Once you're done with a call and want to exit, call leave on the HMSSDK instance you created to join it. Also you can always acquire instance of HMS using build() method.

```js section=LeavingRoom sectionIndex=1
hmsInstance.leave();
```

## Render video

Let us next add a way to show a tile for every participant in the room. We use HmsView component to render video on screen. This component takes trackId and scaleType of HMSVideoTrack and renders the corresponding track. The prop scaleType can be selected from HMSVideoViewMode as required. We can also add mirror a boolean prop as true to flip videos horizontally. Here is a code snippet explaining the way to link a videoTrack to HmsView.

```js section=RenderVideo sectionIndex=1
import { HmsView, HMSVideoViewMode } from 'react-native-hms';

const styles = StyleSheet.create({
    hmsView: {
        height: '100%',
        width: '100%'
    }
});

<HmsView
    style={styles.hmsView}
    trackId={trackId}
    mirror={true}
    scaleType={HMSVideoViewMode.ASPECT_FILL}
/>;
```

There are 2 types of Peers - a localPeer & remotePeers. To extract trackId from peers we can use following code snippet.

```js section=RenderVideo sectionIndex=2
const localTrackId = hmsInstance.localPeer.videoTrack.trackId;

const remoteTrackId = hmsInstance.remotePeers[index].videoTrack.trackId;
```

These track IDs can directly be passed to HmsView component

> A Pro tip: for fastest updates we can use ON_PEER_UPDATE and ON_TRACK_UPDATE listeners, these listeners get updated localPeer and remotePeers whenever there is any event related to these values.

```js section=RenderVideo sectionIndex=3
HmsInstance.addEventListener(HMSUpdateListenerActions.ON_PEER_UPDATE, onPeerListener);

HmsInstance.addEventListener(HMSUpdateListenerActions.ON_TRACK_UPDATE, onTrackListener);

const onPeerListener = ({
    peer,
    type,
}: {
    peer: HMSPeer;
    type: HMSPeerUpdate;
}) => {
  // gets triggered when peer leaves, joins, peer's audio or video is muted, starts or stops speaking, role is changed or becomes dominant speaker.
  // use these objects to update your local and remote peers.
};

const onTrackListener = ({
    track,
    peer,
    type,
}: {
    track: HMSTrack;
    peer: HMSPeer;
    type: HMSTrackUpdate;
}) => {
  // gets triggered when track is added, removed, muted, unmuted, degraded and restored back.
  // use these objects to update your local and remote peers.
};
```

## Mute/Unmute local Audio/Video tracks

Mute is something that applies to both audio and video. When you mute audio, you can't be heard by other people. When you mute video, you will not be broadcasting your video to other people.

It can be invoked only on local (you) peers' audio or video tracks.

You get a reference to your own local peer from localPeer on HMSSDK instance.

```js section=MuteVideo sectionIndex=1
// instance acquired from build() method

hmsInstance.localPeer.localAudioTrack().setMute(true); // audio track

hmsInstance.localPeer.localVideoTrack().setMute(true); // video track
```


### [Github Repo](https://github.com/100mslive/react-native-hms/)
You can checkout the 100ms React Native SDK Github repo which also contains a fully fledged [Example app implementation here](https://github.com/100mslive/react-native-hms/) 



### [Example App](https://github.com/100mslive/react-native-hms/tree/develop/example)

In the [100ms Example App](https://github.com/100mslive/react-native-hms/tree/main/example) we have shown how to setup the various listeners, what data to store in the redux and what all features you can implement.

We have also implemented multiple views which are commonly used. Checkout the [videos & relevant code in the Example app](https://github.com/100mslive/react-native-hms/tree/main/example#additional-features).
