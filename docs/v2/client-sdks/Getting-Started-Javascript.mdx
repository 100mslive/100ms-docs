---
title: Getting Started - JavaScript
nav: 12
---

### Introduction

This guide provides an overview of the key objects you'll use with 100ms' JavaScript SDK to build a live audio/video application

> If you haven't already done so, try our sample [quickstartapp](https://github.com/100mslive/100ms-web-v2). Then you can come back later to see how to build your own live audio/video app in more detail

### Supported Devices

Our alpha release has been tested on modern Chrome browsers. We will expand browser support to all modern browsers soon.

### Basic Concepts

-   `Room` - A room represents a real-time audio, video session, the basic building block of the 100ms Video SDK
-   `Track` - A track represents either the audio or video that makes up a peer's stream
-   `Peer` - A peer represents all participants connected to a room. Peers can be "local" or "remote"
-   `Broadcast` - A local peer can send any message/data to all remote peers in the room

### Pre-requisites

1. **Get the 100ms JS SDK**

```bash
npm install --save @100mslive/hms-video@latest
```

2. **Get Access Keys**: You can get your access keys in the [Developer](https://dashboard.100ms.live/developer) section of [100ms dashboard](https://dashboard.100ms.live)

3. **Create a room and setup a token generation service**: To create a room, follow the steps described [in this section](/v2/server-side/Create-room). To setup a token generation service, follow the steps in [this section](/v2/server-side/Generate-client-side-token). Alternatively, you can use our [quickstart server](/v2/server-side/100ms-quickstart-app-server) for this.

### Import modules & instantiate 100ms Client

```jsx
import { HMSSdk } from '@100mslive/hms-video';

const hms = new HMSSdk();
```

### Provide joining configuration, add listeners and join a room

<Tabs id="join-room" items={['Joining code', 'Room,Peer,Track Interfaces', 'Update Types']} />{' '}

<Code id='join-room-0' tab>

```jsx
const joinConfig = {
    userName: 'Erlich Bachmann',
    authToken: '<Auth token>', //This is the client-side token generated from your token service
    metaData: 'Custom description', //This is a custom data. You can send stringified JSON
    settings: {
        isAudioMuted: false,
        isVideoMuted: false
    }
};

const listener = {
    onJoin(room) {
        // This will be called on a successful JOIN of the room by the user
        // This is the point where applications can stop showing its loading state
        // Parameter room: the room which was joined
        // For now, no events are sent to this callback. Leave this empty
    },
    onRoomUpdate(type, room) {
        // This is called when there is a change in any property of the Room. This is an advanced use case
        // Parameters:
        // type: the triggered update type. Should be used to perform different UI Actions
        // room: the room which was joined
        // check the type tab to see all types
    },
    onPeerUpdate(type, peer) {
        // This will be called whenever there is an update on an existing peer
        // or a new peer got added/existing peer is removed.
        // This callback can be used to keep a track of all the peers in the room
        // Parameters:
        // type: the triggered update type. Should be used to perform different UI Actions
        // peer: the peer who joined/left or was updated
        // .Usually a call to getPeers(), getLocalPeer() is needed here
        // check the type tab to see all types
    },
    onTrackUpdate(type, track, peer) {
        // This is called when there are updates on an existing track
        // or a new track got added/existing track is removed
        // This callback can be used to render the video on screen whenever a track gets added
        // Parameters:
        // type: the triggered update type
        // track: the track which was added, removed or updated
        // peer: the peer for which track was added, removed or updated
        // Usually a call to getPeers(), getLocalPeer() is needed here
        // check the type tab to see all types
    },
    onMessageReceived(message) {
        // This is called when there is a new broadcast message from any other peer in the room
        // This can be used to implement chat is the room
        // Parameter message: the received broadcast message
    },
    onError(error) {
        // This will be called when there is an error in the system
        // and SDK has already retried to fix the error
        // Parameter error: the error that occured
    },
    onReconnecting(error: HMSException) {
        // This is called when connection reestablishment starts
        // This can be used to show a loading notification in the UI
        // Parameter error: the error from the action that failed and caused the connection reestablishment
    },
    onReconnected() {
        // This is called when the connection reestablishment completed susccessfully
    }
};

function onAudioLevelUpdate(speakers) {
    // This is a separate listener that will be updated for listening to audio levels
    // This is optional
}

hms.join(joinConfig, listener);
hms.addAudioListener({ onAudioLevelUpdate: onAudioLevelUpdate });
```

</Code>

<Code id='join-room-1' tab>

```jsx
interface HMSPeer {
    peerId: string;
    name: string;
    isLocal: boolean;
    customerUserId?: string;
    customerDescription: string;
    videoTrack?: HMSTrack | null;
    audioTrack?: HMSTrack | null;
    auxiliaryTracks: HMSTrack[];
    role?: string;
}

interface HMSTrack {
    trackId: string;
    enabled: boolean;
    source?: HMSTrackSource;
    type: HMSTrackType;
    setEnabled(value: boolean): Promise<void>;
}

interface HMSSpeaker {
    peerId: string;
    trackId: string;
    audioLevel: number;
}

interface HMSMessage {
    sender: string;
    receiver?: string;
    time: Date;
    type: HMSMessageType;
    message: string;
}
```

</Code>

<Code id='join-room-2' tab>

```jsx

//this is the enum for type parameter in onPeerUpdate
enum HMSPeerUpdate {
    PEER_JOINED = 0,
    PEER_LEFT = 1,
    BECAME_DOMINANT_SPEAKER = 4,
    RESIGNED_DOMINANT_SPEAKER = 5,
}

//this is the enum for type parameter in onTrackUpdate
enum HMSTrackUpdate {
    TRACK_ADDED = 0,
    TRACK_REMOVED = 1,
    TRACK_MUTED = 2,
    TRACK_UNMUTED = 3,
}

// There are other events yet to be implmeneted, which will fill in the enum gaps
```

</Code>

### Get peers/tracks data

```jsx
const localPeer = hms.getLocalPeer();
const peers = hms.getPeers();
const localVideoTrack = localPeer.videoTrack;
```

### Render video

All audio tracks are rendered automatically by the SDK. As the developer, you just need to render the video track

```jsx
const localVideoTrack = localPeer.videoTrack;
const videoElement = document.getElementById('local-video-id');
localVideoTrack.addSink(videoElement);

//rendering code
<video id="local-video-id" autoplay muted></video>;
```

### Mute/unmute local tracks

```jsx
await localVideoTrack.setEnabled(false);
await localAudioTrack.setEnabled(false);

//On unmuting video, call addSink again to render the video
await localVideoTrack.setEnabled(true);
localVideoTrack.addSink(videoElement);
```

### Sharing screen

```jsx
// Starting screenshare
hms.startScreenshare(onStop);
// onStop is the callback called if user stops the screenshare
// from the system prompt

// Stopping screenshare
hms.stopScreensare();
```

### Leave

```jsx
hms.leave();
```

### Advanced use cases

#### Showing a preview screen before joining

To display a preview of your local stream before joining the call, you can use the `getLocalStream` method provided by the SDK.

This method does NOT publish this video to the room. Publishing `localStream` is handled via the join method

```jsx
import { getLocalStream } from '@100mslive/hms-video';

const previewStream = await getLocalStream({
    audio: { deviceId: selectedAudioInput },
    video: { deviceId: selectedVideoInput }
}); //parameters to the function is a constraints object -
//Refer https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamConstraints

const videoElement = document.getElementById('preview-video-id');
videoElement.srcObject = previewStream;

<video id="preview-video-id" autoplay muted></video>;
```

#### Changing mic/camera before/during the call

```jsx
//Changing before the call
const joinConfig = {
    userName: 'Erlich Bachmann',
    authToken: '<Auth token>', //This is the client-side token generated from your token service
    metaData: 'Custom description', //This is a custom data. You can send stringified JSON
    settings: {
        isAudioMuted: false,
        isVideoMuted: false,
        audioInputDeviceId: 'default';
        videoInputDeviceId: 'default';
    },
};
hms.join(joinConfig, listener);


//Changing midway during the call
localVideoTrack.setSettings({deviceId:'default'});
```

#### Adding / removing auxiliary tracks

To add an auxiliary track\(canvas capture, electron screen-share, etc...\), you can use the addTrack method provided by the SDK. This method adds the track to the local peer's list of auxiliary tracks and publishes it to make it available to remote peers.

```jsx
/**
 * track: MediaStreamTrack - Track to be added
 * source: 'regular' | 'screen' | 'plugin' - Source of track - default: 'regular'
 */
await hms.addTrack(track, source);
```

To remove an auxiliary track, you can use the removeTrack method provided by the SDK. This method removes the track from the local peer's list of auxiliary tracks and unpublishes it.

```jsx
// trackId: ID of the track to be removed
await hms.removeTrack(trackId);
```

> `removeTrack` removes the track only from the list of auxiliary tracks of the local peer. It doesn't remove/unpublish the `audioTrack`/ `videoTrack` of the local peer.
