---
title: Callkit Integration (Beta)
nav: 3.984
---

iOS SDK works well with Apple Callkit framework. With Apple's Callkit framework, your Voip apps can be integrated into iOS native calling experience.

## Minimum Requirements

-   No minimum requirements

## What is Apple Callkit framework?

Callkit is generally used to support making and receiving Voip calls in your audio/video app.

When one person calls another person, your backend can push a silent Voip notification to the callee on their iOS device using APNS (Apple Push Notification Service). You iOS Voip app registers to listen for this notitification using Apple's Pushkit framework. Upon receiving this notification, iOS calls your registered pushkit delegate to handle the notification. You handle the voip notificaiton by reporting an incoming call to the Callkit. Callkit shows the native incoming caller id screen for your app. Once user accepts the call, your callkit delegate is called. At that point you join the meeting with the information in the notification payload.

Similarly, when you make a call, you report Callkit about the call's status so that the system will show the appropriate native UI feedback to the user about the status of the current call.

In both cases, Callkit activates it's audio session exclusive to your app when call is in progress.

### Does 100ms SDK provide special API's for Callkit?

There are no APIs specially for Callkit. You can use 100ms SDK with callkit as ususal, while keeping some things in mind about how callkit's audio session works.

### What to keep in mind when using 100ms SDK with Callkit?

Callkit

1. You create an instance of AVPictureInPictureVideoCallViewController. And add the view that you want to show in PiP window as subview:

```swift
    let pipVideoCallViewController = AVPictureInPictureVideoCallViewController()
    pipVideoCallViewController.view.addSubview(...)
  ```

2. Next, you create a content source from pipVideoCallViewController, passing the target view that PiP window will use as anchor view to animate from (you can optionally set PiP preferred size):

```swift
    let pipContentSource = AVPictureInPictureController.ContentSource(
            activeVideoCallSourceView: targetView,
            contentViewController: pipVideoCallViewController)
            
    // Optionally set the target frame as preferred content size for PiP window
    pipVideoCallViewController.preferredContentSize = targetView.frame.size
  ```
  
3. Then you create AVPictureInPictureController with the content source:

```swift
    let pipController = AVPictureInPictureController(contentSource: pipContentSource)
  ```
  
4. To start the PiP mode, you set pipController to automatically start PiP when the app goes to background or you can use startPictureInPicture function to start PiP manually:

```swift
    // To start PiP automatically when app goes to background
    pipController.canStartPictureInPictureAutomaticallyFromInline = true
            
    // Or you can start PiP manually
    pipController.startPictureInPicture()
  ```
  
### How to display participant's video in PiP

AVPictureInPictureController requires source content to use AVSampleBufferDisplayLayer on it's subview. HMSVideoView uses Metal for rendering video of peers on the call. But because Metal is currently unsupported by AVPictureInPictureController, you can't directly use HMSVideoView to draw participants' video in PiP window. You need to use HMSSampleBufferDisplayView instead. HMSSampleBufferDisplayView is an UIImageView that uses AVSampleBufferDisplayLayer for drawing.

1. You create an instance of HMSSampleBufferDisplayView and set the track to display. You add this as subview to pipVideoCallViewController view:

```swift
    let trackVideoView = HMSSampleBufferDisplayView(frame: .zero)
    trackVideoView.track = track
    
    // Optionally set preferredSize and contentMode
    trackVideoView.preferredSize = CGSize(width: 640.0, height: 480.0)
    trackVideoView.contentMode = .scaleAspectFill
    
    ...
    // As in step 1 in 'How to add PiP support'
    pipVideoCallViewController.view.addSubview(trackVideoView)
  ```
  
2. Set trackVideoView to beging drawing by making it enabled when PiP window is shown (Make it false when PiP window is closed to save resources)

```swift
    trackVideoView.isEnabled = true
    ...
    
    // When PiP window is hidden
    trackVideoView.isEnabled = false
  ```
  
### CPU budget in the background
HMSSampleBufferDisplayView updates it's frame every 0.25 seconds (4 frames per second) to save CPU cycles. This is done to not exceed CPU budget assinged to a background app on iOS. You can experiment and change this update frequency using 'updateEvery' property on HMSSampleBufferDisplayView:

```swift
    // 10 frames per second
    trackVideoView.updateEvery = 0.1
  ```

ðŸ‘€ To see an example iOS Picuture in Picture implementation using 100ms SDK, checkout [our example project](https://github.com/100mslive/100ms-ios-sdk/tree/main/Example).
