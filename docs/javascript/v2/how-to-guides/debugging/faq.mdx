---
title: FAQ
nav: 1.43
---

import Faq from '@/common/faq.md';

This page contains FAQ that are generic to 100ms platform and specific to Web as well:

-   [Common](#general)
-   [Web](#web)

<Faq />

## Web

#### How do I record a room?

We have two types of recordings available, [SFU](/server-side/v2/Destinations/recording) and [Browser](/server-side/v2/Destinations/rtmp-streaming-and-browser-recording).
You can also start the latter from the [SDK](../record-and-live-stream/rtmp-recording).

#### How do I debug blank video tile while rendering?

Start with making sure that attach video is being called for the correct track and video
element. Also ensure that there is no bug leading to detach call just after or around the same time as attach. These calls
when done will also show up in the redux DevTools [extension](./overview#redux-devtools-integration). Some things we have seen in the past -

-   The role was not subscribed properly in the dashboard's templates section
-   [React] Calling detach as a cleanup function of the same useEffect which calls attach and has video track as dependency. Instead of this
    please have a separate useEffect with no dependencies to call detach on component unmount.
-   [React] Not using the [key](https://reactjs.org/docs/lists-and-keys.html) field properly while rendering the list of components displaying
    the track. This should ideally be the `trackId` or `peerId-trackType`, where track type is video or screen.
-   [Angular] Not using the [trackBy](https://angular.io/api/core/TrackByFunction) field properly while rendering the list of components displaying
    the track. This should ideally be the `trackId` or `peerId-trackType`, where track type is video or screen.

#### Why is the video not auto-playing on page load?

For the video to auto-play please make sure these fields are set on the video element - `auto-play`, `muted`, `playsinline`. Please check
the docs for [render video](../set-up-video-conferencing/render-video/overview) for more details.

#### (Angular) Why is video not auto-playing even though muted is set as true?

Angular 2+ is sometimes not able to translate the `muted` field correctly. Instead of setting the muted and auto-play property as
`<video muted>` doing `<video [muted]="true">` should work.
Please check this [Stack Overflow answer](https://stackoverflow.com/questions/48856562/chrome-android-video-autoplay-inside-angular-2-component) for more details.

#### How do I debug no audio coming in the room?

-   Check that the role is being [subscribed to](/concepts/v2/concepts/templates-and-roles/overview#subscribe-strategies) properly in [dashboard's](https://dashboard.100ms.live/) templates section.

-   If your web-app doesn't require a user click to join the room, you might run into auto-play issues. Browsers don't allow a website to play audio if user hasn't interacted with the page till that point in time. Fortunately, we have inbuilt support to detect and resolve this given in more details [here](./error-handling#handling-autoplay-error).

-   If you're using the [setVolume](../control-remote-peers/volume-control) API, it's possible that even though the audio is available it has been locally muted.

#### Is it possible to do RTMP out, live stream a room to YouTube, Twitch, Wowza?

Yes, you can achieve it both from [server-side APIs](/server-side/v2/Destinations/rtmp-streaming-and-browser-recording) or [SDK](../record-and-live-stream/rtmp-recording).

#### What should I do to hide the beam tile showing up in 100ms web-app for browser based recording/streaming?

You can use a viewer role which doesn't have any publish permissions.

#### How do I make the beam bot join with a custom role for dashboard web-app?

You can append a query param in the end of the URL for the custom role - `<custom_role_url>?skip_preview=true`. This
will tell the web-app to skip preview screen and join directly.

#### Why does YouTube dashboard shows that the video bitrate is less than the recommended bitrate when using RTMP Out?

You can safely ignore this, this will happen if there is no activity happening on the URL being streamed. For example, there is nobody in
the room with their video turned on.

#### Can I get HLS out for a room?

Not yet, but we're working on this.

#### How do I join an API created room from dashboard web-app?

You won't see the join room button on the dashboard, but it's possible to form an URL which you can use. The format is
`https://<subdomain>.app.100ms.live/preview/<room_id>/<role>`, For example `https://myroomlink.app.100ms.live/preview/123456/teacher`.
All of these, the subdomain, room_id and role are available on the dashboard.

#### Do I need to do anything to handle poor internet connection?

Not much, just turn on a flag in dashboard, and show a proper UI when a video gets degraded/unsubscribed.
More details [here](../set-up-video-conferencing/render-video/sub-degradation).

#### Can I store extra information with a peer?

Yes you can store [peer metadata](../build-interactive-features/peer-metadata) for a peer. The initial value can be provided at the time of join,
and can be modified post join.

#### How do I implement Raise Hand?

You can do using [peer metadata](../build-interactive-features/peer-metadata).

#### Why do I see videos getting stuck or frozen?

If you have enabled subscribe degradation from the dashboard, the SDK might go in the degradation mode on poor internet connection
turning off some videos to ensure good call quality. When this is done, a flag on the track will be turned on to let the UI know. The UI
should treat it similar to the track turning off for purpose of displaying avatar etc. More details [here](../set-up-video-conferencing/render-video/sub-degradation).

#### Do you have UI components?

Not yet, but it's work in progress for react. Do let us know on discord if you want to sign up for beta and we'll hit you up soon.

#### Can I use the SDK with NextJS, Angular, Svelte, VueJS etc.?

Yes, the core SDK is framework agnostic, you can follow the [JS Quickstart](../../guides/javascript-quickstart) to learn the basics. The quickstart
guide is with vanilla JS and doesn't assume any framework.

#### I want to suggest a new feature.

Awesome, we're always on the lookout for new ideas and feature. Please reach out to us over [discord](https://100ms.live/discord).

#### I'm facing an issue, how do I reach out?

Please see [reaching out](./overview#reaching-out).

#### Can I create room using API?

[Yes](/server-side/v2/Rooms/create-via-api).

#### Can I disable a room?

[Yes](/server-side/v2/Rooms/disable-or-enable). You can also do this while ending the room using the [SDK](../control-remote-peers/end-room).

#### Is it possible to create and manage roles using APIs?

[Yes](/server-side/v2/policy/template-object).

#### Does the SDK remembers input/output device selection for future joins?

Yes, just make sure you pass the `rememberDeviceSelection` as true in the [join config](../set-up-video-conferencing/join).

#### Can I implement custom events to broadcast or sent to a specific person in the room?

Yes, you can do so using our [messaging system](../set-up-video-conferencing/chat#custom-events).

#### How can I access the user id field used while creating the token after joining?

It will be available as `peer.customerUserId` for any peer in the room.

#### How can I implement break out rooms?

This can be done using [roles](https://www.youtube.com/watch?v=aO0KA2w03io).

#### Can I locally mute a remote audio track?

[Yes](../control-remote-peers/volume-control).

#### Can I process video before sending over to others in the room?

Yes, you can write [custom video plugins](../extend-capabilities/plugins/custom-video-plugins).

#### How to disable console logs if I'm using the web SDK?

Please follow [setting log level](./log-level).

#### What is the maximum allowed duration for a session?

The maximum allowed duration for a session on the 100ms platform is 12 hours.

#### How can I get the HLS URL to enable live stream playback?

You can get the HLS URL in several ways based on whether you use 100ms client SDKs or a custom integration for playback; please check the [HLS guide](../../foundation/live-streaming#live-stream-playback) for more information.

#### I get type errors related to WebRTC Stats, for example, 'Cannot find name RTCInboundRtpStreamStats'.

The minimum supported version of TypeScript for the SDK is '4.4'. You could update to any version above 4.4 or if you are on an old version of TypeScript and cannot do a major upgrade you can set `skipLibCheck: true` in your tsconfig file.

#### Why is my screenshare not working on mobile browsers?

The screenshare API(getDisplayMedia) is not yet supported on mobile browsers. Refer [this](https://caniuse.com/?search=getDisplayMedia) for supported browsers.


#### Can I use the sdk to join multiple rooms at the same time?

Yes. Although one instance of SDK can be used to join only one room, you can create multiple instances of the SDK which can operate independently. 
If you're using react-sdk, you can use multiple instances of HMSRoomProvider. A component using hooks from react-sdk will reach out to the nearest HMSRoomProvider in their ancestor tree. For e.g.

``` jsx
const App = () => {
    return (
        <Fragment>
          <HMSRoomProvider>
            <Conference room="room1" />
          </HMSRoomProvider>
          <HMSRoomProvider>
            <Conference room="room2" />
          </HMSRoomProvider>
        </Fragment>
    )
}
```

The above is supported from this [release](https://www.100ms.live/docs/javascript/v2/changelog/release-notes).

Gotchas:

- The app should have separation between the multiple HMSRoomProvider's like the example above.


#### How can I modify noiseSuppression, echoCancellation or autoGainControl on the audio track?

`await hmsActions.setAudioSettings({ advanced:[{ noiseSuppression: false}, { echoCancellation: false }, { autoGainControl: false } ]})`

You can enabled/disable the above properties depending on your use case.
