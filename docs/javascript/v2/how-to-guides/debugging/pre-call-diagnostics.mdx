---
title: Pre Call Diagnostics
nav: 11.4
---

## Pre Call Diagnostic APIs

The Pre Call Diagnostic APIs provide two type of functionalities :

1. APIs to test the connected input and output devices like camera, mic and speaker functionality
2. APIs to test the connectivity to 100ms Servers - This can identify signaling and media connectivity issues and provide a report at the end of the test.

You can use these APIs in your application to detect issues before a Participant joins a video Room or as part of a troubleshooting page while already joined in the room or at a later stage to debug some issues at the end user's device/network

## How to use the Pre Call Diagnostic APIs

To use the diagnostic APIs first you need to initialize an instance of `HMSDiagnostics` from the `HMSActions` instance.

```js
// get the HMSSDK instance
const diagnostics = hmsActions.initDiagnostics();
```

## Request Permissions

If you want a list of devices to choose from before testing your devices you'll need to request corresponding permissions using

```js
diagnostics?.requestPermission({ audio: true, video: true }).catch((error) => setError(error));
```

## Test microphone

To test if the microphone is correctly working, call the `startMicCheck` API passing preffered check duration as `timeInMillis` parameter. Diagnostics SDK will record the microphone input into a temporary file.

You can use the `selectTrackAudioByID` selector to get the input audio level during recording

```js
hmsDiagnostics?.startMicCheck({
    inputDevice,
    onError:,
    onStop,
    time, // in ms, default 10 seconds
});
```

You can call `stopMicCheck` if you need to interrupt the check before the specified time has passed.

## Test speaker

You can check if the speaker is working correctly if you are able to properly play audio using the `HTMLAudioElement` by using the pre-recorded audio file from `startMicCheck` using the `getRecordedAudio` API or use the test audio from `https://100ms.live/test-audio.wav` if such pre-recorded audio is not available.

```js
const element = new HTMLAudioElement();
element.src = hmsDiagnostics?.getRecordedAudio() || 'https://100ms.live/test-audio.wav';
if (typeof element.setSinkId !== 'undefined') {
    // @ts-ignore
    const { audioOutputDeviceId } = hmsStore.getState(selectLocalMediaSettings);
    element.setSinkId(audioOutputDeviceId);
}
element.play();
```

You can set the audio output device ID using HMSActions like `hmsActions.setAudioOutputDevice(deviceId);`

Refer to this file for a full working example to test microphone and speaker in React: https://github.com/100mslive/web-sdks/blob/main/packages/roomkit-react/src/Diagnostics/AudioTest.tsx

## Test Camera

Similar to testing microphone, to check if the camera on the device is working fine, call the `startCameraCheck` API. This API creates a local video track and sets it on the local peer.
Applications can use the `hmsStore` in conjuction with `selectLocalVideoTrackID` to fetch the video track and use `HTMLVideoElement` to show the video track to users, using the same way any other `HMSVideoTrack` is shown.
This API takes the `device` as a parameter, where you can specify either the front or back camera.

```js
await diagnostics?.startCameraCheck(deviceId);
const track = hmsStore.getState(selectLocalVideoTrackID);
await hmsActions.attachVideo(track.id, videoElement);
```

To stop the camera check and release all the resources, call `stopCameraCheck` API

To try a different camera, you can stop and start the camera check again with a different device ID.

Refer to this file for a full working example to test microphone and speaker in React: https://github.com/100mslive/web-sdks/blob/main/packages/roomkit-react/src/Diagnostics/VideoTest.tsx

## Test Connectivity to 100ms Servers

To test if there is proper connectivity to 100ms signalling and media servers, you have to call the `startConnectivityCheck` API. This API establishes connections to both the signalling and media server and publishes audio and video data to determine the network quality and generates a report of the connection.
This API uses the local device's mic and camera to send audio-video data and receives back the same data to calculate network stats for both upload and download link of user's network.
Please note that Camera and microphone permissions are needed to be provided by the app before making a call to this API
This test runs for `20 seconds`. It may finish earlier if connection cannot be established.

While the connectivity test is being performed, regular updates are sent by the SDK via the `progress` callback. The application can listen to these updates and notify the UI to show updates regarding the test.
When the test is completed, `completed` callback is executed with the complete `ConnectivityCheckResult` that has details about all the reports generated.

```js
hmsDiagnostics
    ?.startConnectivityCheck(
        (state) => {
            setProgress(state);
        },
        (result) => {
            setResult(result);
        },
        region
    )
    .catch((error) => {
        setError(error);
    });
```

## Understanding ConnectivityState updates

The `startConnectivityCheck` API sends regular updates while the test is going on. `ConnectivityState` is an enum which has the following states:

```js
enum ConnectivityState {
    STARTING = 0,
    INIT_FETCHED = 1,
    SIGNAL_CONNECTED = 2,
    ICE_ESTABLISHED = 3,
    MEDIA_CAPTURED = 4,
    MEDIA_PUBLISHED = 5,
    COMPLETED = 6
}
```

| Name             | Description                                 |
| ---------------- | ------------------------------------------- |
| STARTING         | Initial state of the connectivity test      |
| INIT_FETCHED     | Init API is fetched successfully            |
| SIGNAL_CONNECTED | Connected to signalling server successfully |
| ICE_ESTABLISHED  | Connected to Media Server successfully      |
| MEDIA_CAPTURED   | Local Media captured successfully           |
| MEDIA_PUBLISHED  | Local media started uploading successfully  |
| COMPLETED        | Connectivity test has completed             |

The above states can be used to show the progress of the test on UI

When the test completes - either successfully or un-successfully, the `completion` callback is executed with the test result in `ConnectivityCheckResult` which has the following fields:
| Name | Description |
| -------------------- | --------------------------------------------------------------------
| `testTimestamp` | Timestamp in millisecond when the test was conducted
| `connectivityState` | The final connectivityState after the test was completed.
| `signallingReport` | Report describing the signalling server connection
| `mediaServerReport` | Report describing the media server connection
| `deviceTestReport` | Report describing the camera, speaker and mic test result
| `errors` | List of `HMSException` that were encountered while performing the test, if any

`HMSSignallingReport` comprises of the following field
| Name | Description |
| -------------------- | --------------------------------------------------------------------
| `isConnected` | whether signalling server was successfully connected or not
| `isInitConnected` | whether test was able to reach INIT server
| `websocketUrl` | The websocket url that was used for the connection to signalling server

`HMSMediaServerReport` comprises of the following field:
| Name | Description |
| ------------------------------------- | --------------------------------------------------------------------
| `isPublishICEConnected` | whether the publish connection to media server was successful
| `isSubcribeICEConnected` | whether the subscribe connection to media server was successful
| `connectionQualityScore` | A floating value denoting the overall network quality of the user. It ranges from 0 to 5, with 5 being the best score
| `stats` | Denotes the overall audio and video stats that was uploaded and downloaded
| `publishIceCandidatesGathered` | A list of all ICE candidates that were gathered for the publish connection
| `subscribeIceCandidatesGathered` | A list of all ICE candidates that were gathered for the subscribe connection
| `publishICECandidatePairSelected` | The candidate pair that was selected for the publish connection
| `subscribeICECandidatePairSelected` | The candidate pair that was selected for the subscribe connection

In the stats, SDK reports the following stats for both audio and video separately in the `stats` field of `HMSMediaServerReport`
| Name | Description
| --------------------- | --------------------------------------------------------------------
| `bytesSent` | Number of video/audio Bytes that were uploaded from the client to SFU
| `bytesReceived` | Number of video/audio Bytes that were downloaded from the SFU
| `packetsReceived` | Number of video/audio packets that were received from the SFU
| `packetsLost` | Number of video/audio packets that were lost while sending to the SFU
| `bitrateSent` | The upload audio/video bitrate in kbps
| `bitrateReceived` | The download or received bitrate of the remote audio/video track in kbps
| `roundTripTime` | The publish side round trip time from the device to the media Server of 100ms. This is same for both audio and video tracks
