---
title: HLS Timed Metadata
nav: 7.22
---

HLS Timed Metadata feature helps you synchronise certain events with the HLS stream. This can be useful for showing interactive quizzes / product overlays etc.

## Requirements

-   Active HLS stream
-   react-sdk min version: 0.3.0

## Sending HLS Timed Metadata

To add HLS timed metadata cue to the currently running HLS stream use `sendHLSTimedMetadata` API like this:
Currently there is a limit to send at max 3 metadata at time. 

```javascript
export interface HLSTimedMetadata {
	payload: string; // limited to 100 chars
	duration: number;
}

sendHLSTimedMetadata(metadatalist: HLSTimedMetadata[]): Promise<void>;
```

## Receiving HLS Timed Metadata
### Receiving Payload structure

The payload is sent in the EXT-X-DATERANGE tag as value for the custom attribure X-100MSLIVE-PAYLOAD. It is base64 encoded string of

```json
{
    "payload": "payload sent by the user",
    "start_date": "2023-02-06T07:24:11.259+0000",
    "end_date": "2023-02-06T07:24:21.259+0000",
    "hms_version": "v1.1"
}
```
start_date and end_date will be in UTC format.

### App side implementation

```javascript
import Hls, { Fragment, LevelParsed } from 'hls.js';
// reference for video element
const videoEl;
const hlsUrl, hls; // reference to hls url
const removeAudioLevels = (levels: LevelParsed[]) => {
  return levels.filter(
    ({ videoCodec, width, height }) => !!videoCodec || !!(width && height)
  );
}
const manifestLoadedHandler = (_: any, { levels }: { levels: LevelParsed[] }) => {
  // get all the quality level present in stream
  const onlyVideoLevels = removeAudioLevels(levels);
};
const levelUpdatedHandler = (_: any, { level }: { level: number }) => {
  // qualityLevel which is currently subscribed to
  const qualityLevel = hls.levels[level];
};
/**
  * Metadata are automatically parsed and added to the video element's
  * textTrack cue by hlsjs as they come through the stream.
  * in FRAG_CHANGED, we read the cues and emit HLS_METADATA_LOADED
  * when the current fragment has a metadata to play.
  */
const fragChangeHandler = (_: any, { frag }: { frag: Fragment }) => {
  try {
    if (videoEl.textTracks.length === 0) {
      return;
    }
    const fragStartTime = frag.start;
    /**
      * this destructuring is needed because the cues array not a pure
      * JS array and prevents us from
      * performing array operations like map(),filter() etc.
      */
    // @ts-ignore
    const metadata = [...videoEl.textTracks[0].cues];
    /**
      * filter out only the metadata that have startTime set to future.
      * (i.e) more than the current fragment's startime.
      */
    const metadataAfterFragStart = metadata.filter(mt => {
      return mt.startTime >= fragStartTime;
    });

    metadataAfterFragStart.forEach(mt => {
      const timeDifference = mt.startTime - fragStartTime;
      const fragmentDuration = frag.end - frag.start;

      if (timeDifference < fragmentDuration) {
        const data = mt.value.data;
        // here we are converting base64 to actual data.
        const payload: Record<string, any> = metadataPayloadParser(data);
        /**
          * we start a timeout for difference seconds.
          * NOTE: Due to how setTimeout works, the time is only the minimum gauranteed
          * time JS will wait before calling emit(). It's not guaranteed even
          * for timeDifference = 0.
          */
        setTimeout(() => {
          /** Even though duration comes as an attribute in the stream,
            * HlsJs doesn't give us a property duration directly. So
            * we calculate it ouselves. This is same as reading
            * EXT-INF tag.
            */
          const duration = mt.endTime - mt.startTime;

          /**
            * finally emit event letting the user know its time to
            * do whatever they want with the payload
            */
          console.log("metadata", {
            payload: payload.payload,
            duration: duration,
          });
        }, timeDifference * 1000);
      }
    });
  } catch (e) {
    console.error('FRAG_CHANGED event error', e);
  }
};
const extractMetaTextTrack = (): TextTrack | null => {
  const textTrackListCount = videoEl?.textTracks.length || 0;
  for (let trackIndex = 0; trackIndex < textTrackListCount; trackIndex++) {
    const textTrack = videoEl?.textTracks[trackIndex];
    if (textTrack?.kind !== 'metadata') {
      continue;
    }
    textTrack.mode = 'showing';
    return textTrack;
  }
  return null;
};
const fireCues = (cues: TextTrackCueList) => {
  const cuesLength = cues.length;
  let cueIndex = 0;
  while (cueIndex < cuesLength) {
    const cue: TextTrackCue = cues[cueIndex];
    if (cue.fired) {
      cueIndex++;
      continue;
    }
    // here we are converting base64 to actual data.
    const data: Record<string, any> = metadataPayloadParser(cue.value.data);
    const programData = videoEl?.getStartDate();
    const startDate = data.start_date;
    const endDate = data.end_date;
    const startTime =
      new Date(startDate).getTime() - new Date(programData).getTime() - (videoEl?.currentTime || 0) * 1000;
    const duration = new Date(endDate).getTime() - new Date(startDate).getTime();
    setTimeout(() => {
      const toast = {
        title: `Payload from timed Metadata ${data.payload}`,
        duration: duration,
      };
      console.debug("Added toast ", JSON.stringify(toast));
    }, startTime);
    cue.fired = true;
    cueIndex++;
  }
};
const handleTimeUpdateListener = () => {
  // extract timed metadata text track
  const metaTextTrack: TextTrack | null = extractMetaTextTrack();
  if (!metaTextTrack || !metaTextTrack.cues) {
    return;
  }
  // fire cue for timed meta data extract
  fireCues(metaTextTrack.cues);
};
if (Hls.isSupported()) {
  /**
   * initialize HLSController and add event listeners.
   */
  hls = new Hls();
  hls.loadSource(hlsUrl);
  hls.attachMedia(videoEl);
  hls.on(Hls.Events.MANIFEST_LOADED, manifestLoadedHandler);
  hls.on(Hls.Events.LEVEL_UPDATED, levelUpdatedHandler);
  hls.on(Hls.Events.FRAG_CHANGED, fragChangeHandler);
} else if (videoEl.canPlayType("application/vnd.apple.mpegurl")) {
  // Work where hls.js is not supported
  videoEl.src = hlsUrl;
  videoEl.addEventListener("timeupdate", handleTimeUpdateListener);
}
```

## Limitations

- It’s hard to sync metadata with stream exactly due to the latency from FFmpeg creating the stream. To address this, we’ve added 2 seconds delay of the actual `START-DATE` attribute.
- The API now allows sending only three metadata objects at once with each having a `payload` string of max length of 100. These can further be tuned based on experimentation.
- The payload cannot have `"`(double quotes). So json won’t be supported. This is a limitation from HLS spec.
