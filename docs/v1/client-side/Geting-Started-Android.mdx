---
title: Getting Started in Android
nav: 7
---

## Introduction

This guide provides an overview of the key objects you'll use with 100ms' android SDK to build a live audio/video application

> If you haven't already done so, try our sample quickstart app. Then you can come back later to see how to build your own live audio/video app in more detail

## Supported Devices

100ms' Android SDK supports Android API level 21 and higher. It is built for armeabi-v7a, arm64-v8a, x86, and x86_64 architectures

---

## Concepts

-   `Room` - A room represents a real-time audio, video session, the basic building block of the 100mslive Video SDK
-   `Stream` - A stream represents real-time audio, video streams that are shared to a room. Usually, each stream contains a video track and an audio track (except screenshare streams, which contains only a video track)
-   `Track` - A track represents either the audio or video that makes up a stream
-   `Peer` - A peer represents all participants connected to a room. Peers can be "local" or "remote"
-   `Publish` - A local peer can share its audio, video by "publishing" its tracks to the room
-   `Subscribe` - A local peer can stream any peer's audio, video by "subscribing" to their streams
-   `Broadcast` - A local peer can send any message/data to all remote peers in the room

---

## Pre-requisites

### ** 1. Add dependency to 100ms lib**

-   Add the JitPack repository to your build file. Add it in your root `build.gradle` at the end of repositories of `allprojects`:

```json
allprojects {
		repositories {
			...
			maven { url 'https://jitpack.io' }
		}
	}
```

-   Add the dependency in your app-level `gradle` [![](https://jitpack.io/v/100mslive/android-sdk.svg)](https://jitpack.io/#100mslive/android-sdk)

```json
dependencies {
		implementation 'com.github.100mslive:android-sdk:x.x.x'
}
```

### **2. Add other dependencies**

Add all the following libraries in your app-level Gradle file as dependencies.

-   If you are using any of the following libraries already in your application, you can use the version you are already using.
-   Make sure `okhttp` and `webrtc` use the same version as mentioned below

```bash
implementation 'org.webrtc:google-webrtc:1.0.32006'
implementation 'com.squareup.okhttp3:okhttp:3.6.0'
implementation 'com.google.code.gson:gson:2.8.6'
implementation 'org.jetbrains:annotations:15.0'
```

### **3. Get Access Keys**

You can get your access keys in the [Developer](https://dashboard.100ms.live/) section of [100ms dashboard](https://dashboard.100ms.live/)

### **4. Generate a server-side token**

To generate a server-side token, follow the steps described [in this section](/v1/server-side/Generate-server-side-token)

### **5. Create a Room**

To create a room, follow the steps described [in this section](/v1/server-side/Create-room)

### **6. Generate a client-side token**

To generate a client-side token, follow the steps described [in this section](/v1/server-side/Generate-client-side-token)

---

## Create and instantiate 100ms Client (HMSClient)

This will instantiate an `HMSClient` object

```java
//Create a 100ms peer
hmspeer = new HMSPeer(username, authToken);
//Create a room
hmsRoom = new HMSRoom(roomId);

//Create client configuration
config = new HMSClientConfig('wss://prod-in.100ms.live/ws');

//Create a 100ms client
hmsClient = new HMSClient(this, getApplicationContext(), hmspeer, config);

hmsClient.setLogLevel(HMSLogger.LogLevel.LOG_DEBUG);
```

> `authTokenis` the client-side token generated by your [token generation service.](/v1/server-side/Generate-client-side-token)

> This `roomId` should be generated using `createRoom` API

---

## Connect to 100ms' server

After instantiating `HMSClient`, connect to 100ms' server.

```java
//The client will connect to the WebSocket channel provided through the config
hmsClient.connect();
```

---

## Setup listeners

After successfully connecting, add listeners to listen to peers joining, new streams being added to the room. This must be done before joining the room.

```java
HMSEventListener listener = new HMSEventListener()
{
		@Override
    public void onConnect() {
       //When the peer connects to the room
    }
		@Override
    public void onDisconnect() {
      //when the peer disconnected from the room
    }
    @Override
    public void onPeerJoin(HMSPeer peer) {
			//call actions related to a new peer addition
    }
    @Override
    public void onPeerLeave(HMSPeer peer) {
			//call actions related to a peer removal
    }
    @Override
    public void onStreamAdd(HMSPeer peer, HMSStreamInfo mediaInfo) {
			// call actions related to a stream addtion
			// call subscribe
		  // peer contains peerId (assigned by 100ms) and customerUserId (assigned by you)
      // mediaInfo contains screen to identify it as a screenshare
    }
    @Override
    public void onStreamRemove(HMSPeer peer, HMSStreamInfo mediaInfo) {
			//call actions related to a stream removal
			//call unsubscribe
    }
    @Override
    public void onBroadcast(HMSPayload payload) {
			//call actions related to a broadcast
    }

    @Override
    public void onDisconnect() {
			//call actions to reconnect
    }

};
```

> Always wait for `'connect'` message handler after creating client before subscribing/publishing any streams

> If say, 4 streams were already published when client connects to the room, then client receives `'stream-add'` messages for all those 4 streams as soon as client joins

> Remember to add `disconnected` message handler. Temporary websocket disconnections are common and trying to reconnect on disconnection will ensure the user sees the conference continuing instead of freezing up

---

## Join a room

```java
//Pass the unique id for the room here as a String
hmsClient.join(roomid, new RequestHandler()
{
	@Override
	public void onSuccess(String data) {
    //data returns roomid
		Log.v("HMSClient onJoinSuccess", data);
	}
	@Override
	public void onFailure(long error, String errorReason) {
		Log.v("HMSClient onJoinFailure", errorReason);
	}
});
```

> This roomId should be generated using createRoom API. Currently, we allow clients to connect to roomIds that have not been created using createRoom API. This access will be removed by end of November

---

## Get local camera/mic streams

```java

//Set all the media constraints here.
//You can disable video/audio publishing by changing the settings from the settings activity
//Do it before joining the room
localMediaConstraints = new HMSRTCMediaStreamConstraints(DEFAULT_PUBLISH_AUDIO, DEFAULT_PUBLISH_VIDEO);
localMediaConstraints.setVideoCodec(DEFAULT_CODEC);
localMediaConstraints.setVideoFrameRate(Integer.valueOf(DEFAULT_VIDEO_FRAMERATE));
localMediaConstraints.setVideoResolution(DEFAULT_VIDEO_RESOLUTION);
localMediaConstraints.setVideoMaxBitRate(Integer.valueOf(DEFAULT_VIDEO_BITRATE));
if(frontCamEnabled){
    isFrontCameraEnabled = true;
    localMediaConstraints.setCameraFacing(FRONT_FACING_CAMERA);
}
else {
    isFrontCameraEnabled = false;
    localMediaConstraints.setCameraFacing(REAR_FACING_CAMERA);
}

hmsClient.getUserMedia(this, localMediaConstraints, new HMSStream.GetUserMediaListener() {

    @Override
    public void onSuccess(HMSRTCMediaStream mediaStream) {				//Receive the local media stream

				 localStream = mediaStream;
				//Expose Media stream APIs to developers
				// process the stream
    }

    @Override
    public void onFailure(String errorReason) {
			Log.v("HMSClient onLeaveFailure", errorReason);
    }
});

```

> The settings above are recommended settings for most use cases. You can increase resolution to hd and bandwidth to 1024 to get higher quality video.

> Getting local screenshare stream will not be covered by v0.x SDK. Please contact support@100ms.live if you want access to sample code to handle it inside your app

---

## Display local stream

Once `mediaStream` has been received, get the video and audio tracks from the stream object. Call the `VideoTrack` , `addsink` method with `SurfaceviewRenderer`.

```java
//The following code is a sample. Developers can make use of the stream object
//in their own way of rendering
if(mediaStream.getStream().videoTracks.size()>0) {
    localVideoTrack = mediaStream.getStream().videoTracks.get(0);
    localVideoTrack.setEnabled(true);
}
if(mediaStream.getStream().audioTracks.size()>0) {
    localAudioTrack = mediaStream.getStream().audioTracks.get(0);
    localAudioTrack.setEnabled(true);
}

runOnUiThread(() -> {
    try {
        surfaceViewRenderer.setVisibility(View.VISIBLE);
        localVideoTrack.addSink(surfaceViewRenderer);
    } catch (Exception e) {
        e.printStackTrace();
    }
});
```

> Remember to mirror the local front facing camera stream but not the main camera stream

---

## Publish local stream to room

A local peer can share her audio, video and data tracks by "publishing" its tracks to the room

```java

hmsClient.publish(localMediaStream, hmsRoom, localMediaConstraints, new HMSStreamRequestHandler() {
@Override
public void onSuccess(HMSPublishStream data) {
    Log.v(TAG, "publish success "+data.getMid());
}

@Override
public void onFailure(long error, String errorReason) {
    Log.v(TAG, "publish failure");
}
});

```

---

## Subscribe to a remote peer's stream

This method "subscribes" to a remote peer's stream. This should ideally be called in the `onStreamAdd` listener.

```java
hmsClient.subscribe(streamInfo, new RequestHandler()
{
	@Override
	public void onSuccess(String data) {
		Log.v("HMSClient onSubscribeSuccess", data);
	}
	@Override
	public void onFailure(long error, String errorReason) {
		Log.v("HMSClient onSubscribeFailure", errorReason);
	}
});
```

> **Identifying screenshare:** Screenshare streams will have the property `isScreen` set to `true` in the corresponding `mediaInfo` passed via `onStreamAdd` event

---

## Broadcast

This method broadcasts a payload to all peers

```java
hmsClient.broadcast(payload, room, new RequestHandler()
{
	@Override
	public void onSuccess(String data) {
		Log.v("HMSClient onBroadcastSuccess", data);
	}
	@Override
	public void onFailure(long error, String errorReason) {
		Log.v("HMSClient onBroadcastFailure", errorReason);
	}
});
```

---

## Unpublish local stream

```java
hmsClient.unpublish(stream, new RequestHandler()
{
	@Override
	public void onSuccess(String data) {
		Log.v("HMSClient onPublishSuccess", data);
	}
	@Override
	public void onFailure(long error, String errorReason) {
		Log.v("HMSClient onPublishFailure", errorReason);
	}
});
```

---

## Unsubscribe to a peer's stream

```java
hmsClient.unsubscribe(stream, new RequestHandler()
{
	@Override
	public void onSuccess(String data) {
		Log.v("HMSClient onUnSubscribeSuccess", data);
	}
	@Override
	public void onFailure(long error, String errorReason) {
		Log.v("HMSClient onUnSubscribeFailure", errorReason);
	}
});
```

---

## Disconnect Client

```java
//The client will disconnect from the WebSocket channel provided
hmsClient.disconnect();
```

---

## Switch Camera

```java
//Toggle between front and rear camera. Make sure you have initialized
//hmsclient before calling this
hmsClient.switchCamera();
```

---

## Mute/unmute local video/audio

Get the local audio/video tracks from hmsClient.getUserMedia() method.

```java

// To mute a local video track
localVideoTrack = mediaStream.getStream().videoTracks.get(0);
localVideoTrack.setEnabled(false);

// To mute a local audio track
localAudioTrack = mediaStream.getStream().audioTracks.get(0);
localAudioTrack.setEnabled(false);

```

This will stop sending video/audio frames to remote peers, however the device camera will still be reported as in use. To stop accessing device camera as well use

```java
HMSStream.getCameraCapturer().stop();
```

Later you can restart camera capture using

```java
HMSStream.getCameraCapturer().start();
```

We recommend adding a delay before calling stop() otherwise the last captured camera frame will keep on showing for remote peers.

```java
localVideoTrack.setEnabled(false);
handler.postDelayed(new Runnable() {
                    @Override
                    public void run() {
                        if (!isVideoEnabled) {
                            HMSStream.getCameraCapturer().stop();
                        }
                    }
                }, 500);
```

---

## Get user id and role

To access the role and user id that were passed in the token use getRole() and getCustomerUserId() getters.

```java
public void onPeerJoin(HMSPeer hmsPeer) {
  Log.v(TAG, "User Id: " + hmsPeer.getCustomerUserId());
  Log.v(TAG, "User Role: " + hmsPeer.getRole());
}
```

---

## Monitor audio levels

To get a periodic update on audio levels for all the parties in the call you can use `startAudioLevelMonitor` API.

First set up the `AudioLevelInfoObserver` which will provide an array of `HMSAudioLevelInfo` that can be used to identify the audio level and map it to the respective stream.

To start receiving callbacks call `startAudioLevelMonitor` passing an update interval. We recommend not going below 500 ms as it can incur performance overhe

<Tabs id="audio-level" items={['Java', 'Kotlin']} />

<Tab  id='audio-level-0'>

```java
// 500 is the interval in milliseconds
client.startAudioLevelMonitor(500, new AudioLevelInfoObserver() {
  @Override
  public void onChange(@NonNull List<HMSAudioLevelInfo> audioInfo) {
    // The audioInfo is sorted in descending order of audio-levels
    // 1st item is dominant speaker
    Log.d(TAG, "startAudioLevelMonitor: "  + audioInfo.toString());
  }
});

// Lambda Expression
client.startAudioLevelMonitor(500, audioInfo -> {
  Log.d(TAG, "startAudioLevelMonitor: "  + audioInfo.toString())
});
```

</Tab>

<Tab id="audio-level-1">

```Kotlin
client.startAudioLevelMonitor(500) { audioInfo ->
  // The audioInfo is sorted in descending order of audio-levels
  // 1st item is dominant speaker
  Log.d(TAG, "startAudioLevelMonitor: $audioInfo")
}
```

</Tab>

When the audio level info is no longer needed call `stopAudioLevelMonitor()`

> Calling `client.disconnect()` will stop the `runningAudioLevelInfoObserver`

---

# Monitor Network Quality Level

To get a periodic update on incoming and outgoing network bitrate you can use the `startNetworkMonitor` API.

First setup the NetworkInfoObserver which will provide an array of `HMSNetworkQualityInfo` , that can be used to identify the `incomingAvailableBitrate` and `outgoingAvailableBitrate` for every peer.

This callback is received every 2000ms

<Tabs id="quality-level" items={['Java', 'Kotlin']} />

<Tab id='quality-level-0'>

```java
// Start
client.startNetworkMonitor(new NetworkInfoObserver() {
  @Override
  public void onChange(@NonNull List<HMSNetworkQualityInfo> networkInfo) {
    HMSNetworkQualityInfo info = networkInfo.get(0);
    Log.d(TAG, "Incoming Bitrate: " + info.getIncomingAvailableBitrate());
    Log.d(TAG, "Outgoing Bitrate: " + info.getOutgoingAvailableBitrate());
    Log.d(TAG, "Peer Id: " + info.getPeerId());
  }
});

// Lambda Expression
client.startNetworkMonitor(networkInfo -> {
  HMSNetworkQualityInfo info = networkInfo.get(0);
});

// Stop
client.stopNetworkMonitor()
```

</Tab>

<Tab  id='quality-level-1'>

```Kotlin
// Start
client.startNetworkMonitor { networkInfo ->
  val info: HMSNetworkQualityInfo = networkInfo.get(0)
  Log.d(TAG, "Incoming Bitrate: " + info.incomingAvailableBitrate)
  Log.d(TAG, "Outgoing Bitrate: " + info.outgoingAvailableBitrate)
  Log.d(TAG, "Peer Id: " + info.peerId)
}

// Stop
client.stopNetworkMonitor()
```

</Tab>

> For now there is only one peer's info that is being set, which is the local peer.
