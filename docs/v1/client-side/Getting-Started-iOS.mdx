---
title: Getting Started iOS
---

# Getting started - iOS

---

## Introduction

This guide provides an overview of the key objects you'll use with 100ms' iOS SDK to build a live audio/video application.

> If you haven't already done so, try our [sample quickstart app.](https://github.com/100mslive/100ms-ios) Then you can come back later to see how to build your own live audio/video app in more detail

---

## Supported Devices

100ms' iOS SDK supports iOS 10.0+ and higher. Use Xcode 11+ for development

---

## Pre-requisites

### 1. Add 100ms iOS SDK

**CocoaPods**

[CocoaPods](https://cocoapods.org/) is a dependency manager for Cocoa projects. For usage and installation instructions, visit their [website](https://guides.cocoapods.org/using/getting-started.html). To integrate 100ms' SDK into your Xcode project using CocoaPods, specify it in your Podfile:

`pod 'HMSVideo', '~> 0.10.0'`

### **2. Get Access Keys**

You can get your access keys in the [Developer](https://dashboard.100ms.live/) section of [100ms dashboard](https://dashboard.100ms.live/)

### **3. Generate a server-side token**

To generate a server-side token, follow the steps described [in this section](/v1/server-side/Generate-server-side-token)

### **4. Create a Room**

To create a room, follow the steps described [in this section](/v1/server-side/Create-room)

### **5. Generate a client-side token**

To generate a client-side token, follow the steps described [in this section](/v1/server-side/Generate-client-side-token)

---

## Concepts

-   `Room` - A room represents a real-time audio, video session, the basic building block of the 100mslive Video SDK
-   `Stream` - A stream represents real-time audio, video streams that are shared to a room. Usually, each stream contains a video track and an audio track (except screenshare streams, which contains only a video track)
-   `Track` - A track represents either the audio or video that makes up a stream
-   `Peer` - A peer represents all participants connected to a room. Peers can be "local" or "remote"
-   `Publish` - A local peer can share its audio, video by "publishing" its tracks to the room
-   `Subscribe` - A local peer can stream any peer's audio, video by "subscribing" to their streams
-   `Broadcast` - A local peer can send any message/data to all remote peers in the room

---

## Create and instantiate HMSClient (100ms Client)

This will instantiate an `HMSClient` object

```
//Create an HMSPeer instance for local peer
let peer = HMSPeer(name: userName, authToken: "INSERT TOKEN HERE")
// let peer = HMSPeer(name: userName, authToken: "INSERT TOKEN HERE", customerDescription: "Your Custom Meta Data Peer Description.")


let config = HMSClientConfig()
//config.endpoint = "Override endpoint URL if needed"

//Create a 100ms video client
let client = HMSClient(peer: peer, config: config)
```

> Use wss://prod-in.100ms.live as endpoint URL

> `authToken` is the client-side token generated by your token generation service.

---

## Setup listeners

After joining, immediately add listeners to listen to peers joining, new streams being added to the room.

```swift
client.onPeerJoin = { room, peer in
    // Update UI if needed
}

client.onPeerLeave = { room, peer in
    // Update UI if needed
}

client.onStreamAdd = { room, peer, streamInfo in
    // Subscribe to the stream if needed
    // peer contains peerId (assigned by 100ms) and customerUserId (assigned by you)
    // streamInfo contains screen to identify it as a screenshare

}

client.onStreamRemove = { room, peer, streamInfo in
    // Remove remote stream view if needed
}

client.onBroadcast = { room, peer, message in
    // update UI if needed
}

client.onConnect = {
		// Client connected, this is a good place to call join(room)
}

client.onDisconnect = { error in
		// Connection lost or could not be established.
		// Good place to retry or show an error to the user.
}
```

> Always wait for 'onConnect' listener after creating client before subscribing/publishing any streams.

> If say, 4 streams were already published when a client connects to the room, then the client receives 'onStreamAdd' listener messages for all those 4 streams as soon as client joins.

> Remember to add onDisconnect listener. Temporary WebSocket disconnections are common and trying to reconnect on disconnection will ensure the user sees the conference continuing instead of freezing up

## Connect

After instantiating `HMSClient`, connect to 100ms' server

```swift
//The client will connect to the WebSocket channel provided through the config
client.connect()
```

---

## Join a Room

```swift
//Pass the unique id for the room here as a String
let room = HMSRoom(roomId: roomName)

client.join(room) { success, error in
    //check for error and publish a local stream
}
```

> This `roomId` should be generated using `createRoom` API

---

## Create and Get local camera/mic streams

```swift
//You can set codec, bitrate, framerate, etc here.
let constraints = HMSMediaStreamConstraints()
constraints.shouldPublishAudio = true
constraints.shouldPublishVideo = true
constraints.codec = .VP8
constraints.bitrate = 256 //Maximum bitrate consumed for the video
constraints.audioBitrate = 30
constraints.frameRate = 20
constraints.resolution = .QVGA //This determines video width and height. Possible values - qqvga, qvga, shd, hd

let localStream = try? client.getLocalStream(constraints)
```

> Please use the following settings for a video that looks good in postcard-sized videos - codec:VP8, bitrate 256, framerate 20. We will extend this in the future to add more options including front/back camera.

<Note>

Apple requires your app to provide static messages to display to the user when the system asks for camera or microphone permission:

If your app uses device cameras, include theNSCameraUsageDescription key in your app’s Info.plist file.

If your app uses device microphones, include theNSMicrophoneUsageDescription key in your app’s Info.plist file.

For each key, provide a message that explains to the user why your app needs to capture media so that the user can feel confident granting permission to your app.

If the appropriate key is not present in your app’s Info.plist file when your app requests authorisation or attempts to use a capture device, the system terminates your app.

</Note>

> Getting local screen-share stream will not be covered by v0.x SDK. Please contact support@100ms.live if you want access to sample code to handle it inside your app

---

## Display a stream

```swift
//The following code is a sample.

//Get the video capturer and video track
let videoCapturer = stream.videoCapturer
let localVideoTrack = stream.videoTracks?.first

//Begin capturing video from the camera
videoCapturer?.startCapture()

//Create a view for rendering video track and add to the UI hierarchy
if let track = localVideoTrack {
    let videoView = HMSVideoView()
		videoView.setVideoTrack(track)
		view.addSubview(videoView)
}
```

---

## Publish

A local participant can share her audio, video and data tracks by "publishing" its tracks to the room

```swift
client.publish(localStream, room: room) { stream, error in
    //Handle error if any, update UI if needed
}
```

---

## Subscribe

This method "subscribes" to a peer's stream. This should ideally be called in the `onStreamAdd` listener.

```swift
client.subscribe(streamInfo, room: room) { stream, error in
	//Handle error if any, update UI if needed
}
```

> Screenshare streams will have the property screen set totrue in the corresponding `streamInfo` passed via `onStreamAdd` event

---

## Broadcast

This method broadcasts a payload to all participants

```swift
client.broadcast(message, room: room) { stream, error in
	//Handle error if any, update UI if needed
}
```

---

## Unpublish local stream

```swift
client.unpublish(stream, room: room) { stream, error in
	//Handle error if any, update UI if needed
}
```

---

## Unsubscribe to a peer's stream

```swift
client.unsubscribe(stream, room: room) { stream, error in
//Handle error if any, update UI if needed
}
```

---

## Disconnect client

````swift
//The client will disconnect from the WebSocket channel provided
client.disconnect()```
````

---

## Mute/unmute local video/audio

Assuming you have a stored reference to the previously obtained local HMSStream (see here) to mute a video or audio set enabled property to false on respective track.

```swift
// To mute a local video track
let localVideoTrack = localStream.videoTracks?.first
localVideoTrack?.enabled = false

// To mute a local audio track
let localAudioTrack = localStream.audioTracks?.first
localAudioTrack?.enabled = false
```

---

## Switch between front/back camera

Assuming you have a stored reference to the previously obtained local HMSStream (see here) to switch camera device get the video capturer from the stream and call `switchCamera()`

```swift
let videoCapturer = localStream.videoCapturer
videoCapturer.switchCamera()
```

---

## Adjust local stream parameters mid-call

---

## Monitor audio levels

To get a periodic update on audio levels for all the parties in the call you can use `startAudioLevelMonitor` API.

First set up the onAudioLevelInfo callback handler

```swift
client.onAudioLevelInfo = { [weak self] (infoArray) in
    guard let topLevel = infoArray.first else {
        return;
    }
    guard let peer = self?.peers[topLevel.streamId] else {
        return
    }
    self?.speakerLabel.text = "Dominant speaker: \(peer.name)";
}
```

The callback will provide an array of `HMSAudioLevelInfo` object which can be used to identify the audio level and map it to the respective stream.

To start receiving callbacks call startAudioLevelMonitor passing an update interval. We recommend not going below 0.5 sec as it can incur performance overhead.

```swift
client.startAudioLevelMonitor(0.5); // interval in seconds
```

When the audio level info is no longer needed call `stopAudioLevelMonitor()`.

---

## Adjust local stream parameters mid-call

Assuming you have a stored reference to the previously obtained local `HMSStream` (see here) to change the stream parameters create a new `HMSMediaStreamConstraints` instance and call apply the function of the `HMSClient`.

```swift
//You can only change video bitrate, audio bitrate, frame rate, resolution
//parameters mid call. Other properties will be ignored.œ
let constraints = HMSMediaStreamConstraints()
constraints.bitrate = 512
constraints.frameRate = 25
constraints.resolution = .VGA

client.apply(constraints, toLocalStream: localStream)
```
