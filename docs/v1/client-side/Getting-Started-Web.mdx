---
title: Getting Stated in Web
---

# Introduction

This guide provides an overview of the key objects you'll use with 100ms' JavaScript SDK to build a live audio/video application.

> If you haven't already done so, try our sample quickstart app. Then you can come back later to see how to build your own live audio/video app in more detail

---

## Supported Devices

| Platform             | Chrome              | Firefox             | Opera               | Safari              |
| -------------------- | ------------------- | ------------------- | ------------------- | ------------------- |
| Android 4.4 or later | Version 73 or later | Version 73 or later | Version 45 or later | No                  |
| MacOS 10 or later    | Version 73 or later | Version 73 or later | Version 45 or later | Version 11 or later |
| Windows 7 or later   | Version 73 or later | Version 73 or later | Version 45 or later | No                  |
| iOS                  | Yes                 | No                  | No                  | Version 14          |

---

## Concepts

-   `Room` - A room represents a real-time audio, video session, the basic building block of the 100mslive Video SDK
-   `Stream` - A stream represents real-time audio, video streams that are shared to a room. Usually, each stream contains a video track and an audio track (except screenshare streams, which contains only a video track)
-   `Track` - A track represents either the audio or video that makes up a stream
-   `Peer` - A peer represents all participants connected to a room. Peers can be "local" or "remote"
-   `Publish` - A local peer can share its audio, video by "publishing" its tracks to the room
-   `Subscribe` - A local peer can stream any peer's audio, video by "subscribing" to their streams
-   `Broadcast` - A local peer can send any message/data to all remote peers in the room

---

## Pre-requisites

### **1. Get the 100ms JavaScript SDK**

```bash
npm install --save @100mslive/hmsvideo-web@latest
```

### **2. Get Access Keys**

You can get your access keys in the [Developer](https://dashboard.100ms.live/) section of [100ms dashboard](https://dashboard.100ms.live/)

### **3. Generate a server-side token**

To generate a server-side token, follow the steps described [in this section](/v1/server-side/Generate-server-side-token)

### **4. Create a Room**

To create a room, follow the steps described [in this section](/v1/server-side/Create-room)

### **5. Generate a client-side token**

To generate a client-side token, follow the steps described [in this section](/v1/server-side/Generate-client-side-token)

---

## Import modules & instantiate 100ms Client (HMSClient)

```js
import { HMSPeer, HMSClientConfig, HMSClient } from '@100mslive/hmsvideo-web';

const peer = new HMSPeer(userName, authToken, 'Your Custom Meta Data Peer Description.');

const config = new HMSClientConfig({
    endpoint: 'wss://prod-in.100ms.live'
});

const client = new HMSClient(peer, config);
```

> `authTokenis` the client-side token generated by your [token generation service.](/v1/server-side/Generate-client-side-token)

---

## Connect to 100ms' server

After instantiating `HMSClient`, connect to 100ms' server

```js
try {
    await client.connect();
} catch (err) {
    // Handle error
}
```

---

## Setup listeners

Add listener functions to listen to peers joining, establishing a connection to the server, peers publishing their streams etc.

```js
client.on('connect', () => {
    // This is where we can call `join(room)`
});

client.on('disconnect', (reason) => {
    // the reason would be 'CONNECTION_CLOSED' if it was closed normally
    // the reason would be 'ERR_CONNECTION_REFUSED' if we are unable to connect
});

client.on('peer-join', (room, peer) => {
    // Show a notification or toast message in the UI
});

client.on('peer-leave', (room, peer) => {
    // Show a notification or toast message in the UI
});

client.on('stream-add', (room, peer, streamInfo) => {
    // subscribe to the stream if needed
    // peer contains peerId (assigned by 100ms) and customerUserId (assigned by you)
    // streamInfo contains screen to identify it as a screenshare
});

client.on('stream-remove', (room, peer, streamInfo) => {
    // Remove remote stream if needed
});

client.on('broadcast', (room, peer, message) => {
    // Show a notification or update chat UI
});

client.on('disconnected', () => {
    // If there is a temporary websocket disconnection, then execute code
    // to re-publish and subscribe all streams. eg. location.reload();
});
```

> Always wait for `'connect'` message listener after creating client before subscribing/publishing any streams

> If say, 4 streams were already published when client connects to the room, then client receives `'stream-add'` messages for all those 4 streams as soon as client joins

> Remember to add `disconnected` message handler. Temporary websocket disconnections are common and trying to reconnect on disconnection will ensure the user sees the conference continuing instead of freezing up

---

## Get a local stream

This method prompts the user for permission to use a media input that produces audio/video tracks such as a camera, screen, microphone

### Connect to default devices

```js
const localStream = await client.getLocalStream({
    resolution: 'vga',
    bitrate: 256,
    codec: 'VP8',
    frameRate: 20,
    shouldPublishAudio: true,
    shouldPublishVideo: true
});
```

### Connect to specific device

In order to connect to a specific camera/mic, you can use the advancedMediaConstraints key which accepts browser's native [MediaStreamConstraints](https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamConstraints) as shown below. To get deviceIDs, use [enumerateDevices](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/enumerateDevices)

```js
const localStream = await client.getLocalStream({
    resolution: 'vga', //This defines the video height and width. Can be qqvga, qvga, shd, hd
    bitrate: 256, //This is the maximum bitrate to cap the video at
    codec: 'VP8',
    frameRate: 20,
    shouldPublishAudio: true,
    shouldPublishVideo: true,
    advancedMediaConstraints: {
        video: {
            deviceId: 'e82934fe80bdd62ed2aac541f5fd53e53d98abb0b738c6f52edea4f5014d32d8'
        },
        audio: {
            deviceId: '756814e591e116616c740e39b307a8015cac4c2511950e0240cf7fbe62736dfd'
        }
    }
});
```

> For advanced use cases: all stream objects returned by getLocalStream extends browser's native MediaStream class and implements all its methods

> The settings above are recommended settings for most use cases. You can increase resolution to hd and bitrate to 1024 to get higher quality video. Available resolution settings: qqvga, qvga, vga, shd, hd

---

## Get local media for screenshare

This method prompts the user for permission to share their screen and choose the screnshare source

```js
const localScreen = await client.getLocalScreen({
    bitrate: 0,
    codec: 'VP8',
    frameRate: 10
});

//If your primary usecase is sharing text

localScreen.getVideoTracks().forEach((track) => {
    if ('contentHint' in track) {
        track.contentHint = 'text';
    }
});
```

---

## Display local stream

All stream objects can be attached to HTML video elements. eg. The local stream from the user's camera

```jsx
//This is React implementation.
//Replace ref, useRef with id, getElementById for native HTML implementation.

//Create a reference for the video element to which the local stream will be attached
const localVideo = useRef();

//Attach local stream to the video element
localVideo.current.srcObject = local;

//Add video element
<video autoPlay muted ref={localVideo}></video>;
```

> Remember to set `muted` to `true` and mirror the local webcam stream

---

## Publish local stream to room

```js
try {
    await client.publish(local, roomId);
} catch (err) {
    // handle the error
}
```

> A client can publish multiple streams eg. a screenshare, an in-built webcam and an external webcam all together

---

## Subscribe to a remote peer's stream

This method "subscribes" to a remote peer's stream. This should ideally be called in the `stream-add` message listener

```js
try {
    const remote = await client.subscribe(mid, roomId);
    // Do something with remote stream
} catch (err) {
    // Handle error
}
```

> **Identifying screenshare:** Screenshare streams will have the property `screen` set to `true` in the corresponding streamInfo passed viastream-add message

---

## Unsubscribe to a peer's stream

```js
try {
    await client.unsubscribe(remoteStream, roomId);
} catch (err) {
    // Handle error
}
```

## Broadcast a payload to the room

```js
try {
    await client.broadcast(payload, roomId);
} catch (err) {
    // Handle error
}
```

---

## Disconnect client

```js
client.disconnect();
```

---

## Mute/unmute local video/audio

100ms SDK's `Stream` interface has `mute` and `unmute` methods provided to mute and unmute video or audio respectively.

```js
// To mute local stream audio
local.mute('audio');

// To unmute local stream audio
local.unmute('audio');

// To mute local stream video
local.mute('video');

// To unmute local stream video
local.unmute('video');
```

---

## Change quality of audio/video mid-stream

You can use applyConstraints to change the quality/source of the video mid-stream.

### Change quality

```js
client.applyConstraints(
    {
        bitrate: 0,
        codec: 'VP8',
        resolution: 'hd',
        frameRate: 10
    },
    localStream
);
```

> You need to send only those constraints that need to be changed in `client.applyConstraints` function.

---

## Monitor audio levels

To get a periodic update on audio levels for all the parties in the call you can use `startAudioLevelMonitor` API.

First set up the callback handler

```js
function onAudioLevelInfo(infoArray) {
    // Use hmsAudioInfo
}
```

The callback will provide an array of `HMSAudioLevelInfo` object which can be used to identify the audio level and map it to the respective stream.

To start receiving callbacks call `startAudioLevelMonitor` passing an update interval. We recommend not going below 0.5 sec as it can incur performance overhead.

```js
client.startAudioLevelMonitor(0.5, onAudioLevelInfo); // interval in seconds
```

When the audio level info is no longer needed call `stopAudioLevelMonitor()`.
